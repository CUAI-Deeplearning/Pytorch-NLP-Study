{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 10 신경망 기계번역"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1 기계번역\n",
    "\n",
    "- seq2seq\n",
    "- 어텐션"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.1 번역의 목표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{e} = argmax P_{f \\rightarrow e} (e|f)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 번역이 어려운 이유\n",
    "- 언어의 모호성\n",
    "- 문화의 차이"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.2 기계번역의 역사"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 규칙 기반 기계번역(RBMT)\n",
    "\n",
    "- 구조를 분석해서 얻은 규칙을 통해서 번역\n",
    "- 한계\n",
    "    - 규칙을 사람이 일일이 찾아야해서 많은 자원과 시간 소모\n",
    "    - 번역 언어쌍을 확장할 때 매우 불리\n",
    "    \n",
    "#### 통게 기반 기계번역(SMT)\n",
    "\n",
    "- 대량의 양방향 코퍼스에서 통계를 얻어내 번역 시스템 구성\n",
    "- 언어쌍을 확장할 때 대부분의 알고리즘과 시스템은 유지되서 RBMT보다 유리\n",
    "\n",
    "#### 딥러닝 이전의 신경망 기계번역\n",
    "\n",
    "- 오토인코더 기반: 인코더 $\\rightarrow$ 디코더\n",
    "- 성능 매우 떨어짐\n",
    "\n",
    "#### 딥러닝 이후의 신경망 기계번역\n",
    "\n",
    "장점\n",
    "1. end-to-end 모델  \n",
    "    여러 모듈로 복잡하게 나눠지지 않고 하나의 모델로 번역을 해서 성능 극대화\n",
    "2. 더 나은 언어 모델  \n",
    "    n-gram의 단점이었던 희소성 문제를 NNLM으로 해결, 자연스러운 번역 결과 생성 강점\n",
    "3. 훌륭한 문장 임베딩  \n",
    "    임베딩 벡터 만들어내는 능력이 뛰어나기 때문에 노이즈나 희소성 문제 더 잘 대처"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2 seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.1 구조 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(Y|X;\\theta)$를 최대로 하는 모델 파라미터를 찾고 사후 확률을 최대로 하는 $Y$를 찾는다.\n",
    "\n",
    "$$\\hat{\\theta} = \\argmax_\\theta P(Y|X;\\theta) \\ where \\ X = \\{x_1, x_2, \\dots, x_n\\}, Y = \\{y_1, y_2, \\dots, y_m\\}$$\n",
    "$$\\hat{Y} = \\argmax_{Y \\in \\mathcal{Y}}P(Y|X;\\theta)$$\n",
    "\n",
    "seq2seq는 **인코더**, **디코더**, **생성자**로 구성\n",
    "\n",
    "#### 인코더\n",
    "\n",
    "- 소스 문장으로부터 문장 임베딩 벡터를 만들어낸 후 $P(z|X)$를 모델링\n",
    "- 주어진 문장을 매니폴드를 따라 차원 축소하여 해당 도메인의 잠재 공간의 어떤 하나의 점에 투영하는 작업\n",
    "- 기계번역을 위한 문장 임베딩 벡터를 생성하려면 최대한 많은 정보를 갖고 있어야 함.\n",
    "\n",
    "▶ 인코더 수식\n",
    "\n",
    "$$h_t^{src} = RNN_{enc}(emb_{src}(x_t), h_{t-1}^{src})$$\n",
    "$$H^{src} = [h_1^{src};h_2^{src};\\dots;h_n^{src}]$$\n",
    "\n",
    "▶ 전체 time-step 병렬 처리했을 때\n",
    "\n",
    "$$H^{src} = RNN_{src}(emb_{src}(X), h_0^{src})$$\n",
    "\n",
    "#### 디코더\n",
    "\n",
    "조건부 신경망 언어 모델(CNNLM)\n",
    "\n",
    "▶ seq2seq 모델 수식 time-step에 관해 풀었을 때\n",
    "$$P_{\\theta}(Y|X) = \\prod_{t=1}^m P_{\\theta}(y_t|X,y_{<t})$$\n",
    "$$logP_{\\theta}(Y|X) = logP_{\\theta}(y_t|X,y_{<t})$$\n",
    "\n",
    "- RNNLM에서 조건부 확률 변수 부분에 X가 추가된 모습\n",
    "- 인코더의 결과인 문장 임베딩 벡터와 이전 time-step까지 번역하여 생성한 단어들에 기반하여 현재 time-step의 단어 생성\n",
    "\n",
    "▶ 디코더 수식\n",
    "$$h_t^{tgt} = RNN_{dec}(emb_{tgt}(y_{t-1}), h_{t-1}^{tgt})$$\n",
    "$$where \\ h_0^{tgt} = h_n^{tgt} and y_0 = BOS$$\n",
    "\n",
    "#### 생성자\n",
    "\n",
    "디코더에서 각 time-step별로 결과 벡터 $h_t^{tgt}$를 받아 softmax를 계산하여, 각 타깃 언어의 단어별 확률값을 반환\n",
    "\n",
    "▶ 생성자 수식\n",
    "\n",
    "$$\\hat{y}_t = softmax(linear_{hs \\to |V_{tgt}|}(h_t^{tgt})) and \\hat{y}_m = EOS$$\n",
    "$$where \\ hs \\ is \\ hidden \\ size \\ of \\ RNN, \\ and \\ |V_{tgt}| \\ is \\ size \\ of \\ output \\ vocabulary$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.2. seq2seq의 활용 분야"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기계번역, 챗봇, 요약, 기타 자연어 처리, 음성 인식, 독순술, 이미지 캡셔닝 등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.3 한계점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 장기 기억력\n",
    "\n",
    "정보를 압축하는데 한계가 있다보니까 시퀀스가 길어질수록 성능이 떨어진다.\n",
    "\n",
    "#### 구조 정보의 부재\n",
    "\n",
    "현재는 문장을 단순히 시퀀스 데이터로 다루고 있지만, 나중에는 구조 정보도 필요할 것이다.\n",
    "\n",
    "#### 챗봇 또는 QA봇\n",
    "\n",
    "번역이나 요약 문제의 경우에는 새롭게 추가되는 정보가 거의 없어서 잘 수행했지만, 대화의 경우에는 지식이나 맥락 등 추가되는 정보가 있기 때문에 한계가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.4. 파이토치 예제 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 인코더 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, word_vec_dim, hidden_size, n_layers=4, dropout_p=.2):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.rnn = nn.LSTM(word_vec_dim,\n",
    "                           int(hidden_size / 2),\n",
    "                           num_layers=n_layers,\n",
    "                           dropout=dropout_p,\n",
    "                           bidirectional=True,\n",
    "                           batch_first=True\n",
    "                           )\n",
    "        \n",
    "    def forward(self, emb):\n",
    "        if isinstance(emb, tuple):\n",
    "            x, lengths = emb\n",
    "            x = pack(x, lenghts.tolist(), batch_first=True)\n",
    "        \n",
    "        else:\n",
    "            x = emb\n",
    "            \n",
    "        y, h = self.rnn(x)\n",
    "    \n",
    "        if isinstance(emb, tuple):\n",
    "            y, _ = unpack(y, batch_first=True)\n",
    "        \n",
    "        return y, h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  pack_padded_sequence 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [torch.tensor([1, 2, 3]), torch.tensor([3, 4]), torch.tensor([1])]\n",
    "b = torch.nn.utils.rnn.pad_sequence(a, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1, 2, 3]), tensor([3, 4]), tensor([1])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [3, 4, 0],\n",
       "        [1, 0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([1, 3, 1, 2, 4, 3]), batch_sizes=tensor([3, 2, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.utils.rnn.pack_padded_sequence(b, batch_first=True, lengths=[3, 2, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 디코더 클래스\n",
    "\n",
    "어텐션 이후에"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 생성자 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.softmax(self.output(x))\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전체 seq2seq 클래스\n",
    "\n",
    "어텐션 이후"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 손실 함수\n",
    "\n",
    "교차 엔트로피 함수\n",
    "\n",
    "실제 구현에서는 **softmax + 교차 엔트로피**보다 **logsoftmax + 음의 로그 가능도(NLL)**를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_weight = torch.ones(output_size)\n",
    "loss_weight[data_loader.PAD] = 0.\n",
    "\n",
    "crit = nn.NLLLoss(weight=loss_weight,\n",
    "                  reduction='sum',\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_loss(self, y_hat, y, crit=None):\n",
    "    crit = self.crit if crit is None else crit\n",
    "    loss = crit(y_hat.contiguous().view(-1, y_hat.size(-1)),\n",
    "                y.contiguous().view(-1))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```contiguous()```: 특정 축 잘라내는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0,  1,  2,  3,  4,  5],\n",
      "          [ 6,  7,  8,  9, 10, 11]],\n",
      "\n",
      "         [[12, 13, 14, 15, 16, 17],\n",
      "          [18, 19, 20, 21, 22, 23]]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1*2*2*6).view(-1,2,2,6)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17],\n",
      "        [18, 19, 20, 21, 22, 23]])\n"
     ]
    }
   ],
   "source": [
    "x = x.view(-1,6)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 6,  7,  8,  9],\n",
      "        [12, 13, 14, 15],\n",
      "        [18, 19, 20, 21]])\n"
     ]
    }
   ],
   "source": [
    "x = x[:,:4].contiguous()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3 어텐션"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.1 어텐션 이해하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "쿼리와 비슷한 값을 가진 키를 찾아서 값을 얻는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.2 key-value 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {'computer': 9, 'dog': 2, 'cat': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_value_func(query):\n",
    "    weights = []\n",
    "    \n",
    "    for key in dic.keys():\n",
    "        weights += [is_same(key, query)]\n",
    "        \n",
    "    weight_sum = sum(weights)\n",
    "    for i,w in enumerate(weights):\n",
    "        weights[i] = weights[i] / weight_sum\n",
    "        \n",
    "    answer = 0\n",
    "    \n",
    "    for weight, value in zip(weights, dic.values()):\n",
    "        answer += weight *  value\n",
    "        \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_same(key, query):\n",
    "    if key == query:\n",
    "        return 1.\n",
    "    else:\n",
    "        return 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for k in dic.keys():\n",
    "    print(is_same(k, \"computer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n"
     ]
    }
   ],
   "source": [
    "print(key_value_func(\"computer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.3 연속적인 key-value 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.4 연속적인 key-value 벡터 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.5 기계번역에서의 어텐션"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인코더의 각 time-step별 출력을 키와 밸류로 삼고, 현재 time-step의 디코더 출력을 쿼리로 삼아 어텐션 계산\n",
    "\n",
    "▶ 어텐션을 추가한 seq2seq 수식\n",
    "\n",
    "$$w = softmax(h_t^{tgtT}W \\cdot H^{src})$$\n",
    "$$c = H^{src} \\cdot w \\  and c \\ is \\ a\\ context \\ vector$$\n",
    "$$\\tilde{h}_t^{tgt} = tanh(linear_{2 \\times hs \\to hs}([h_t^{tgt};c]))$$\n",
    "$$\\hat{y}_t = softmax(linear_{hs \\to |V_{tgt}|}(\\tilde{h}_t^{tgt}))$$\n",
    "$$where \\ hs \\ is \\ hidden \\ size \\ of \\ RNN, \\ and \\ |V_{tgt}| \\ is \\ size \\ of \\ output \\ vocabulary$$\n",
    "\n",
    "- 원하는 정보를 어텐션을 통해 인코더에서 획득한 후, 해당 정보를 디코더의 출력과 이어붙여 tanh를 취한 후, softmax 계산을 통해 다음 time-step의 입력이 되는 $\\hat y_t$을 구한다.\n",
    "\n",
    "<img src=\"https://blobscdn.gitbook.com/v0/b/gitbook-28427.appspot.com/o/assets%2F-LFzjkZt6ljMBd4YGVCn%2F-LX4NCwvtTXyg_vzXhF0%2F-LX4NFi6LreOTrZ3dcWF%2F10-03-01.png?generation=1548425967953999&alt=media\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 선형 변환\n",
    "\n",
    "소스 언어와 대상 언어가 애초부터 다르기 때문에 선형 관계가 있다고 가정하고 내적을 수행하기 전에 선형 변환을 해준다. $W$는 선형 변환을 위한 신경망 가중치 파라미터이다.\n",
    "\n",
    "어텐션이 필요한 이유는 문장이 길어질수록 은닉 상태만으로 모든 정보를 완벽하게 전달할 수 없는 문제 때문이다. 따라서 디코더의 time-step마다 현재 디코더의 은닉 상태에 따라 필요한 인코더의 정보에 접근해서 사용하겠다는 것이다.\n",
    "\n",
    "선형 변환을 배우는 것 자체를 어텐션이라고 표현할 수 있다. 이는 디코더의 현재 상태에 따라 필요한 쿼리를 만들어내고, 인코더의 key 값들과 비교해서 가중합을 하는 과정이기 때문이다.\n",
    "\n",
    "선형 변환을 위한 가중치 파라미터가 훈련되면, 디코더의 상태 자체도 선형 변환에 좋은 방향으로 RNN이 동작할 것이다.\n",
    "\n",
    "#### 선형 변환 결과\n",
    "\n",
    "어텐션을 적용한 것이 성능이 더 좋았고, 특히 문장이 길어질수록 성능이 떨어지는 점이 덜해졌다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.6 파이토치 예제 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```torch.bmm()```: 배치 행렬 곱을 수행하는 함수, 뒤의 두개의 차원에 대해 행렬 곱을 수행하기 때문에 이 부분의 차원은 행렬 곱에 적합한 크기여야 하고, 앞의 차원들은 배치로 취급해서 같은 크기여야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 2, 4]), torch.Size([10, 4, 6]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.arange(80).view(10, 2, 4)\n",
    "y = torch.arange(240).view(10, 4, 6)\n",
    "\n",
    "x.size(), y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |x| = (10, 2, 4)\n",
    "# |y| = (10, 4, 6)\n",
    "\n",
    "z = torch.bmm(x, y)\n",
    "# |z| = (10, 2, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2, 6])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 어텐션 클래스\n",
    "\n",
    "선형 변환을 위한 가중치 파라미터를 편향이 없는 선형 계층으로 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \n",
    "    def __init(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, h_src, h_t_tgt, mask=None):\n",
    "        query = self.linear(h_t_tgt.squeeze(1)).unsqueeze(-1)\n",
    "        \n",
    "        weight = torch.bmm(h_src, query).squeeze(-1)\n",
    "        \n",
    "        if mask is not None:\n",
    "            weight.masked_fill_(mask, -float('inf'))\n",
    "        weight = self.softmax(weight)\n",
    "        \n",
    "        context_vector = torch.bmm(weight.unsqueeze(1), h_src)\n",
    "        \n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
