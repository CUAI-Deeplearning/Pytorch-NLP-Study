{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 10 신경망 기계번역"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1 기계번역\n",
    "\n",
    "- seq2seq\n",
    "- 어텐션"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.1 번역의 목표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{e} = argmax P_{f \\rightarrow e} (e|f)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 번역이 어려운 이유\n",
    "- 언어의 모호성\n",
    "- 문화의 차이"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.2 기계번역의 역사"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 규칙 기반 기계번역(RBMT)\n",
    "\n",
    "- 구조를 분석해서 얻은 규칙을 통해서 번역\n",
    "- 한계\n",
    "    - 규칙을 사람이 일일이 찾아야해서 많은 자원과 시간 소모\n",
    "    - 번역 언어쌍을 확장할 때 매우 불리\n",
    "    \n",
    "#### 통게 기반 기계번역(SMT)\n",
    "\n",
    "- 대량의 양방향 코퍼스에서 통계를 얻어내 번역 시스템 구성\n",
    "- 언어쌍을 확장할 때 대부분의 알고리즘과 시스템은 유지되서 RBMT보다 유리\n",
    "\n",
    "#### 딥러닝 이전의 신경망 기계번역\n",
    "\n",
    "- 오토인코더 기반: 인코더 $\\rightarrow$ 디코더\n",
    "- 성능 매우 떨어짐\n",
    "\n",
    "#### 딥러닝 이후의 신경망 기계번역\n",
    "\n",
    "장점\n",
    "1. end-to-end 모델  \n",
    "    여러 모듈로 복잡하게 나눠지지 않고 하나의 모델로 번역을 해서 성능 극대화\n",
    "2. 더 나은 언어 모델  \n",
    "    n-gram의 단점이었던 희소성 문제를 NNLM으로 해결, 자연스러운 번역 결과 생성 강점\n",
    "3. 훌륭한 문장 임베딩  \n",
    "    임베딩 벡터 만들어내는 능력이 뛰어나기 때문에 노이즈나 희소성 문제 더 잘 대처"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2 seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.1 구조 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(Y|X;\\theta)$를 최대로 하는 모델 파라미터를 찾고 사후 확률을 최대로 하는 $Y$를 찾는다.\n",
    "\n",
    "$$\\DeclareMathOperator*{\\argmax}{argmax}$$\n",
    "$$\\hat{\\theta} = \\argmax_\\theta P(Y|X;\\theta) \\ where \\ X = \\{x_1, x_2, \\dots, x_n\\}, Y = \\{y_1, y_2, \\dots, y_m\\}$$\n",
    "$$\\hat{Y} = \\argmax_{Y \\in \\mathcal{Y}}P(Y|X;\\theta)$$\n",
    "\n",
    "seq2seq는 **인코더**, **디코더**, **생성자**로 구성\n",
    "\n",
    "#### 인코더\n",
    "\n",
    "- 소스 문장으로부터 문장 임베딩 벡터를 만들어낸 후 $P(z|X)$를 모델링\n",
    "- 주어진 문장을 매니폴드를 따라 차원 축소하여 해당 도메인의 잠재 공간의 어떤 하나의 점에 투영하는 작업\n",
    "- 기계번역을 위한 문장 임베딩 벡터를 생성하려면 최대한 많은 정보를 갖고 있어야 함.\n",
    "\n",
    "▶ 인코더 수식\n",
    "\n",
    "$$h_t^{src} = RNN_{enc}(emb_{src}(x_t), h_{t-1}^{src})$$\n",
    "$$H^{src} = [h_1^{src};h_2^{src};\\dots;h_n^{src}]$$\n",
    "\n",
    "▶ 전체 time-step 병렬 처리했을 때\n",
    "\n",
    "$$H^{src} = RNN_{src}(emb_{src}(X), h_0^{src})$$\n",
    "\n",
    "#### 디코더\n",
    "\n",
    "조건부 신경망 언어 모델(CNNLM)\n",
    "\n",
    "▶ seq2seq 모델 수식 time-step에 관해 풀었을 때\n",
    "$$P_{\\theta}(Y|X) = \\prod_{t=1}^m P_{\\theta}(y_t|X,y_{<t})$$\n",
    "$$logP_{\\theta}(Y|X) = logP_{\\theta}(y_t|X,y_{<t})$$\n",
    "\n",
    "- RNNLM에서 조건부 확률 변수 부분에 X가 추가된 모습\n",
    "- 인코더의 결과인 문장 임베딩 벡터와 이전 time-step까지 번역하여 생성한 단어들에 기반하여 현재 time-step의 단어 생성\n",
    "\n",
    "▶ 디코더 수식\n",
    "$$h_t^{tgt} = RNN_{dec}(emb_{tgt}(y_{t-1}), h_{t-1}^{tgt})$$\n",
    "$$where \\ h_0^{tgt} = h_n^{tgt} and y_0 = BOS$$\n",
    "\n",
    "#### 생성자\n",
    "\n",
    "디코더에서 각 time-step별로 결과 벡터 $h_t^{tgt}$를 받아 softmax를 계산하여, 각 타깃 언어의 단어별 확률값을 반환\n",
    "\n",
    "▶ 생성자 수식\n",
    "\n",
    "$$\\hat{y}_t = softmax(linear_{hs \\to |V_{tgt}|}(h_t^{tgt})) and \\hat{y}_m = EOS$$\n",
    "$$where \\ hs \\ is \\ hidden \\ size \\ of \\ RNN, \\ and \\ |V_{tgt}| \\ is \\ size \\ of \\ output \\ vocabulary$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.2. seq2seq의 활용 분야"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기계번역, 챗봇, 요약, 기타 자연어 처리, 음성 인식, 독순술, 이미지 캡셔닝 등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.3 한계점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 장기 기억력\n",
    "\n",
    "정보를 압축하는데 한계가 있다보니까 시퀀스가 길어질수록 성능이 떨어진다.\n",
    "\n",
    "#### 구조 정보의 부재\n",
    "\n",
    "현재는 문장을 단순히 시퀀스 데이터로 다루고 있지만, 나중에는 구조 정보도 필요할 것이다.\n",
    "\n",
    "#### 챗봇 또는 QA봇\n",
    "\n",
    "번역이나 요약 문제의 경우에는 새롭게 추가되는 정보가 거의 없어서 잘 수행했지만, 대화의 경우에는 지식이나 맥락 등 추가되는 정보가 있기 때문에 한계가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.4. 파이토치 예제 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 인코더 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, word_vec_dim, hidden_size, n_layers=4, dropout_p=.2):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.rnn = nn.LSTM(word_vec_dim,\n",
    "                           int(hidden_size / 2),\n",
    "                           num_layers=n_layers,\n",
    "                           dropout=dropout_p,\n",
    "                           bidirectional=True,\n",
    "                           batch_first=True\n",
    "                           )\n",
    "        \n",
    "    def forward(self, emb):\n",
    "        if isinstance(emb, tuple):\n",
    "            x, lengths = emb\n",
    "            x = pack(x, lenghts.tolist(), batch_first=True)\n",
    "        \n",
    "        else:\n",
    "            x = emb\n",
    "            \n",
    "        y, h = self.rnn(x)\n",
    "    \n",
    "        if isinstance(emb, tuple):\n",
    "            y, _ = unpack(y, batch_first=True)\n",
    "        \n",
    "        return y, h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  pack_padded_sequence 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [torch.tensor([1, 2, 3]), torch.tensor([3, 4]), torch.tensor([1])]\n",
    "b = torch.nn.utils.rnn.pad_sequence(a, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1, 2, 3]), tensor([3, 4]), tensor([1])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [3, 4, 0],\n",
       "        [1, 0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([1, 3, 1, 2, 4, 3]), batch_sizes=tensor([3, 2, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.utils.rnn.pack_padded_sequence(b, batch_first=True, lengths=[3, 2, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 디코더 클래스\n",
    "\n",
    "어텐션 이후에"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 생성자 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.softmax(self.output(x))\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전체 seq2seq 클래스\n",
    "\n",
    "어텐션 이후"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 손실 함수\n",
    "\n",
    "교차 엔트로피 함수\n",
    "\n",
    "실제 구현에서는 **softmax + 교차 엔트로피**보다 **logsoftmax + 음의 로그 가능도(NLL)**를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_weight = torch.ones(output_size)\n",
    "loss_weight[data_loader.PAD] = 0.\n",
    "\n",
    "crit = nn.NLLLoss(weight=loss_weight,\n",
    "                  reduction='sum',\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_loss(self, y_hat, y, crit=None):\n",
    "    crit = self.crit if crit is None else crit\n",
    "    loss = crit(y_hat.contiguous().view(-1, y_hat.size(-1)),\n",
    "                y.contiguous().view(-1))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```contiguous()```: 특정 축 잘라내는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0,  1,  2,  3,  4,  5],\n",
      "          [ 6,  7,  8,  9, 10, 11]],\n",
      "\n",
      "         [[12, 13, 14, 15, 16, 17],\n",
      "          [18, 19, 20, 21, 22, 23]]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1*2*2*6).view(-1,2,2,6)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17],\n",
      "        [18, 19, 20, 21, 22, 23]])\n"
     ]
    }
   ],
   "source": [
    "x = x.view(-1,6)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 6,  7,  8,  9],\n",
      "        [12, 13, 14, 15],\n",
      "        [18, 19, 20, 21]])\n"
     ]
    }
   ],
   "source": [
    "x = x[:,:4].contiguous()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3 어텐션"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.1 어텐션 이해하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "쿼리와 비슷한 값을 가진 키를 찾아서 값을 얻는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.2 key-value 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {'computer': 9, 'dog': 2, 'cat': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_value_func(query):\n",
    "    weights = []\n",
    "    \n",
    "    for key in dic.keys():\n",
    "        weights += [is_same(key, query)]\n",
    "        \n",
    "    weight_sum = sum(weights)\n",
    "    for i,w in enumerate(weights):\n",
    "        weights[i] = weights[i] / weight_sum\n",
    "        \n",
    "    answer = 0\n",
    "    \n",
    "    for weight, value in zip(weights, dic.values()):\n",
    "        answer += weight *  value\n",
    "        \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_same(key, query):\n",
    "    if key == query:\n",
    "        return 1.\n",
    "    else:\n",
    "        return 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for k in dic.keys():\n",
    "    print(is_same(k, \"computer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n"
     ]
    }
   ],
   "source": [
    "print(key_value_func(\"computer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.3 연속적인 key-value 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.4 연속적인 key-value 벡터 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.5 기계번역에서의 어텐션"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인코더의 각 time-step별 출력을 키와 밸류로 삼고, 현재 time-step의 디코더 출력을 쿼리로 삼아 어텐션 계산\n",
    "\n",
    "▶ 어텐션을 추가한 seq2seq 수식\n",
    "\n",
    "$$w = softmax(h_t^{tgtT}W \\cdot H^{src})$$\n",
    "$$c = H^{src} \\cdot w \\  and c \\ is \\ a\\ context \\ vector$$\n",
    "$$\\tilde{h}_t^{tgt} = tanh(linear_{2 \\times hs \\to hs}([h_t^{tgt};c]))$$\n",
    "$$\\hat{y}_t = softmax(linear_{hs \\to |V_{tgt}|}(\\tilde{h}_t^{tgt}))$$\n",
    "$$where \\ hs \\ is \\ hidden \\ size \\ of \\ RNN, \\ and \\ |V_{tgt}| \\ is \\ size \\ of \\ output \\ vocabulary$$\n",
    "\n",
    "- 원하는 정보를 어텐션을 통해 인코더에서 획득한 후, 해당 정보를 디코더의 출력과 이어붙여 tanh를 취한 후, softmax 계산을 통해 다음 time-step의 입력이 되는 $\\hat y_t$을 구한다.\n",
    "\n",
    "<img src=\"https://blobscdn.gitbook.com/v0/b/gitbook-28427.appspot.com/o/assets%2F-LFzjkZt6ljMBd4YGVCn%2F-LX4NCwvtTXyg_vzXhF0%2F-LX4NFi6LreOTrZ3dcWF%2F10-03-01.png?generation=1548425967953999&alt=media\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 선형 변환\n",
    "\n",
    "소스 언어와 대상 언어가 애초부터 다르기 때문에 선형 관계가 있다고 가정하고 내적을 수행하기 전에 선형 변환을 해준다. $W$는 선형 변환을 위한 신경망 가중치 파라미터이다.\n",
    "\n",
    "어텐션이 필요한 이유는 문장이 길어질수록 은닉 상태만으로 모든 정보를 완벽하게 전달할 수 없는 문제 때문이다. 따라서 디코더의 time-step마다 현재 디코더의 은닉 상태에 따라 필요한 인코더의 정보에 접근해서 사용하겠다는 것이다.\n",
    "\n",
    "선형 변환을 배우는 것 자체를 어텐션이라고 표현할 수 있다. 이는 디코더의 현재 상태에 따라 필요한 쿼리를 만들어내고, 인코더의 key 값들과 비교해서 가중합을 하는 과정이기 때문이다.\n",
    "\n",
    "선형 변환을 위한 가중치 파라미터가 훈련되면, 디코더의 상태 자체도 선형 변환에 좋은 방향으로 RNN이 동작할 것이다.\n",
    "\n",
    "#### 선형 변환 결과\n",
    "\n",
    "어텐션을 적용한 것이 성능이 더 좋았고, 특히 문장이 길어질수록 성능이 떨어지는 점이 덜해졌다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.6 파이토치 예제 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```torch.bmm()```: 배치 행렬 곱을 수행하는 함수, 뒤의 두개의 차원에 대해 행렬 곱을 수행하기 때문에 이 부분의 차원은 행렬 곱에 적합한 크기여야 하고, 앞의 차원들은 배치로 취급해서 같은 크기여야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 2, 4]), torch.Size([10, 4, 6]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.arange(80).view(10, 2, 4)\n",
    "y = torch.arange(240).view(10, 4, 6)\n",
    "\n",
    "x.size(), y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |x| = (10, 2, 4)\n",
    "# |y| = (10, 4, 6)\n",
    "\n",
    "z = torch.bmm(x, y)\n",
    "# |z| = (10, 2, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2, 6])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 어텐션 클래스\n",
    "\n",
    "선형 변환을 위한 가중치 파라미터를 편향이 없는 선형 계층으로 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \n",
    "    def __init(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, h_src, h_t_tgt, mask=None):\n",
    "        query = self.linear(h_t_tgt.squeeze(1)).unsqueeze(-1)\n",
    "        \n",
    "        weight = torch.bmm(h_src, query).squeeze(-1)\n",
    "        \n",
    "        if mask is not None:\n",
    "            weight.masked_fill_(mask, -float('inf'))\n",
    "        weight = self.softmax(weight)\n",
    "        \n",
    "        context_vector = torch.bmm(weight.unsqueeze(1), h_src)\n",
    "        \n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.4 input feeding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- softmax 이전의 값을 임베딩 벡터에 이어붙여 디코더의 RNN의 입력으로 넣는다.\n",
    "- 이유: softmax를 해서 샘플링하는 과정에서 많은 정보가 손실되기 때문\n",
    "\n",
    "▶ 어텐션과 input feeding이 추가된 seq2seq 수식\n",
    "\n",
    "$$h_t^{src} = RNN_{enc}(emb_{src}(x_t),h_{t-1}^{src})$$\n",
    "$$H^{src} = [h_1^{src};h_2^{src};\\dots;h_n^{src}]$$\n",
    "$$h_t^{tgt} = RNN_{dec}([emb_{tgt}(y_{t-1});\\tilde{h}_{t-1}^{tgt}],h_{t-1}^{tgt}) \\ where \\ h_0^{tgt} = h_n^{src} \\ and \\ y_0 = BOS$$\n",
    "$$w = softmax(h_t^{tgtT}W \\cdot H^{src})$$\n",
    "$$c = H^{src} \\cdot w \\ and \\ c \\ is \\ a \\ context \\ vector$$\n",
    "$$h_t^{tgt} = tanh(linear_{2hs \\to hs} ([h_t^{tgt};c]))$$\n",
    "$$\\hat{y}_t = softmax(linear_{hs \\to |V_{tgt}|} (\\tilde {h}_t^{tgt}))$$\n",
    "$$where \\ hs \\ is \\ hidden \\ size \\ of \\ RNN, \\ and \\ |V_{tgt}| \\ is \\ size \\ of \\ output \\ vocabulary$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.1 단점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 훈련 속도 저하: 디코더 RNN의 입력으로 이전 time-step의 결과($\\tilde{h}_t^{tgt}$)가 필요해서 time-step 별로 순차적으로 처리\n",
    "- 하지만 추론 과정에서는 병렬 처리가 거의 불가능하기 때문에 크게 부각되진 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.2 성능 개선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어텐션과 input feeding을 사용해서 기본 모델보다 더 나은 성능 보임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.3 구현 관점에서 바라보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※ 각 텐서의 크기 생각해보기\n",
    "\n",
    "1. 소스 문장과 타깃 문장으로 이루어진 병렬 코퍼스\n",
    "\n",
    "$$B = \\{X_i, Y_i\\}_{i=1}^N$$\n",
    "$$ where \\ X = \\{x_1, \\dots, x_n\\}, Y = \\{y_1, \\dots, y_m\\}$$\n",
    "\n",
    "2. 인코더에 넣고 피드포워드하는 과정\n",
    "\n",
    "    ▶ 1 time-step의 경우\n",
    "$$h_t^{src} = RNN_{enc}(emb_{src}(x_t),h_{t-1}^{src})$$\n",
    "\n",
    "    ▶ 병렬 처리\n",
    "$$H^{src} = [h_1^{src};h_2^{src};\\dots;h_n^{src}] = RNN_{enc}(emb_{src}(X),h_0^{src})$$\n",
    "\n",
    "\n",
    "3. 디코더의 피드포워드\n",
    "\n",
    "$$h_t^{tgt} = RNN_{dec}([emb_{tgt}(y_{t-1});\\tilde{h}_{t-1}^{tgt}], h_{t-1}^{tgt})$$\n",
    "$$where \\ h_0^{tgt} = h_n^{src} \\ and \\ y_0 = BOS$$\n",
    "\n",
    "4. 어텐션 가중치\n",
    "\n",
    "$$w = softmax(H^{src} \\cdot (h_t^{tgt} \\cdot W))$$\n",
    "\n",
    "5. 어텐션 가중치에 따라 가중합 구하는 과정\n",
    "\n",
    "$$c = w \\cdot H^{src}$$\n",
    "\n",
    "6. input-feeding\n",
    "\n",
    "$$\\tilde{h}_t^{tgt} = tanh(linear_{2hs \\to hs}([h_t^{tgt};c]))$$\n",
    "\n",
    "7. 소프트맥스 계층을 통과시켜 확률값 구하기\n",
    "\n",
    "$$\\DeclareMathOperator*{\\argmax}{argmax}$$\n",
    "$$P(y_t|X,y_{<t};\\theta) = softmax(linear_{hs \\to |V_tgt|}(\\tilde{h}_t^{tgt}))$$\n",
    "$$\\hat{y}_t = \\argmax_{y \\in \\mathcal{Y}} P(y_t|X,y_{<t};\\theta)$$\n",
    "\n",
    "8. 손실함수\n",
    "\n",
    "$$\\mathcal{L}(\\theta) = - \\frac 1 N \\sum_{i=1}^N y_t^i \\cdot logP(y_t|X_i,y_{<t}^t;\\theta)$$\n",
    "\n",
    "9. 파라미터 업데이트\n",
    "\n",
    "$$\\theta \\leftarrow \\theta - \\gamma \\nabla_{\\theta}\\mathcal{L}_{\\theta}(\\hat{Y}, Y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.4 파이토치 예제 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 어텐션 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, h_src, h_t_tgt, mask=None):\n",
    "        query = self.linear(h_t_tgt.squeeze(1)).unsqueeze(-1)\n",
    "        \n",
    "        weight = torch.bmm(h_src, query).squeeze(-1)\n",
    "        \n",
    "        if mask is not None:\n",
    "            weight.masked_fill_(mask, -float('inf'))\n",
    "        weight = self.softmax(weight)\n",
    "        \n",
    "        context_vector = torch.bmm(weight.unsqueeze(1), h_src)\n",
    "        \n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 어텐션을 위한 마스크 생성\n",
    "\n",
    "- 미니배치의 크기는 가장 긴 문장의 크기에 좌우됨\n",
    "- 짧은 문장들은 문장의 종료 후 패딩으로 채워짐\n",
    "- 이런 미니배치가 어텐션 연산을 수행하면 단어가 존재하지 않는 곳인데 디코더에게 쓸데없이 정보를 넘겨주게 됨\n",
    "- 따라서 이 부분의 어텐션 가중치를 다시 0으로 만들어주는 작업 필요\n",
    "- 마스크 부분을 음의 무한대 값을 줘서 softmax를 통과했을 때 0이 되도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq2seq 클래스 내부에 정의된 마스크 생성 함수\n",
    "def generate_mask(self, x, length):\n",
    "    mask = []\n",
    "    \n",
    "    max_length = max(length)\n",
    "    for l in length:\n",
    "        if max_length - l > 0:\n",
    "            mask += [torch.cat([x.new_ones(1, l).zero_(),\n",
    "                                x.new_ones(1, (max_length-1))\n",
    "                               ], dim=-1)]\n",
    "        else:\n",
    "            mask += [x.new_ones(1, l).zero_()]\n",
    "            \n",
    "    mask = torch.cat(mask, dim=0).byte()\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 인코더 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, word_vec_dim, hidden_size, n_layers=4, dropout_0=.2):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.rnn = nn.LSTM(word_vec_dim,\n",
    "                           int(hidden_size/2),\n",
    "                           num_layers=n_layers,\n",
    "                           dropout=dropout_p,\n",
    "                           bidirectional=True,\n",
    "                           batch_first=True\n",
    "                          )\n",
    "        \n",
    "    def forward(self, emb):\n",
    "        if isinstance(emb, tuple):\n",
    "            x, lengths = emb\n",
    "            x = pack(x, lengths.tolist(), batch_first=True)\n",
    "            \n",
    "        else:\n",
    "            x = emb\n",
    "            \n",
    "        y, h = self.rnn(x)\n",
    "        \n",
    "        if isinstance(emb, tuple):\n",
    "            y, _ = unpack(y, batch_first=True)\n",
    "            \n",
    "        return y, h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 디코더 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, word_vec_dim, hidden_size, n_layers=4, dropout=.2):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.rnn = nn.LSTM(word_vec_dim + hidden_size,\n",
    "                           hidden_size,\n",
    "                           num_layers=n_layers,\n",
    "                           dropout=dropout_p,\n",
    "                           bidirectional=False,\n",
    "                           batch_first=True\n",
    "                          )\n",
    "        \n",
    "    def forward(self, emb_t, h_t_1_tilde, h_t_1):\n",
    "        batch_size = emb_t.size(0)\n",
    "        hidden_size = h_t_1[0].size(-1)\n",
    "        \n",
    "        if h_t_1_tilde is None:\n",
    "            h_t_1_tilde = emb_t.new(batch_size, 1, hidden_size).zero_()\n",
    "            \n",
    "        x = torch.cat([emb_t, h_t_1_tilde], dim=-1)\n",
    "        \n",
    "        y, h = self.rnn(x, h_t_1)\n",
    "        \n",
    "        return y, h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 생성자 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.softmax(self.output(x))\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### seq2seq 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 word_vec_dim,\n",
    "                 hidden_size,\n",
    "                 output_size,\n",
    "                 n_layers=4,\n",
    "                 dropout_p=.2\n",
    "                 ):\n",
    "        self.input_size = input_size\n",
    "        self.word_vec_dim = word_vec_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        \n",
    "        super(Seq2Seq, self).__init__()\n",
    "        \n",
    "        self.emb_src = nn.Embedding(input_size, word_vec_dim)\n",
    "        self.emb_dec = nn.Embedding(ouput_size, word_vec_dim)\n",
    "        \n",
    "        self.encoder = Encoder(word_vec_dim,\n",
    "                               hidden_size,\n",
    "                               n_layers=n_layers,\n",
    "                               dropout_p=dropout_p\n",
    "                               )\n",
    "        self.decoder = Decoder(word_vec_dim,\n",
    "                               hidden_size,\n",
    "                               n_layers=n_layers,\n",
    "                               dropout_p=dropout_p\n",
    "                               )\n",
    "        self.attn = Attention(hidden_size)\n",
    "        \n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.generator = Generator(hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 인코더의 은닉 상태를 디코더의 은닉 상태로 변환하기\n",
    "\n",
    "인코더는 양방향 LSTM을 사용했기 때문에 텐서의 위치를 조작하여 디코더의 은닉 상태에 알맞은 형태로 변환해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_encoder_hiddens(self, encoder_hiddens):\n",
    "    new_hiddens = []\n",
    "    new_cells = []\n",
    "    \n",
    "    hiddens, cells = encoder_hiddens\n",
    "    \n",
    "    for i in range(0, hiddens.size(0), 2):\n",
    "        new_hiddens += [torch.cat([hiddens[i], hiddens[i + 1]], dim=-1)]\n",
    "        new_cells += [torch.cat([cells[i], cells[i + 1]], dim=-1)]\n",
    "        \n",
    "    new_hiddens, new_cells = torch.stack(new_hiddens), torch.stack(new_cells)\n",
    "    \n",
    "    return (new_hiddens, new_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반복문을 사용하지 않는 방법\n",
    "h_0_tgt, c_0_tgt = h_0_tgt\n",
    "h_0_tgt = h_0_tgt.transpose(0, 1).contiguous().view(batch_size,\n",
    "                                                    -1,\n",
    "                                                    self.hidden_size\n",
    "                                                    ).transpose(0, 1).contiguous()\n",
    "c_0_tgt = c_0_tgt.transpose(0, 1).contiguous().view(batch_size,\n",
    "                                                    -1,\n",
    "                                                    self.hidden_size\n",
    "                                                    ).transpose(0, 1).contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 포워드 함수 정의\n",
    "\n",
    "seq2seq에서 인코더는 모든 time-step을 한번에 연산하지만, 디코더는 input feeding 때문에 반복문을 사용해서 타깃 문장의 길이만큼 time-step 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, src, tgt):\n",
    "    batch_size = tgt.size(0)\n",
    "    \n",
    "    mask = None\n",
    "    x_length = None\n",
    "    if isinstance(src, tuple):\n",
    "        x, x_length = src\n",
    "        mask = self.generate_mask(x, x_length)\n",
    "    \n",
    "    else:\n",
    "        x = src\n",
    "    \n",
    "    if isinstance(tgt, tuple):\n",
    "        tgt = tgt[0]\n",
    "        \n",
    "    emb_src = self.emb_src(x)\n",
    "    \n",
    "    h_src, h_0_tgt = self.encoder((emb_src, x_length))\n",
    "    \n",
    "    h_0_tgt, c_0_tgt = h_0_tgt\n",
    "    h_0_tgt = h_0_tgt.transpose(0, 1).contiguous().view(batch_size,\n",
    "                                                        -1,\n",
    "                                                        self.hidden_size\n",
    "                                                        ).transpose(0, 1).contiguous()\n",
    "    c_0_tgt = c_0_tgt.transpose(0, 1).contiguous().view(batch_size,\n",
    "                                                        -1,\n",
    "                                                        self.hidden_size\n",
    "                                                        ).transpose(0, 1).contiguous()\n",
    "    \n",
    "    h_0_tgt = (h_0_tgt, c_0_tgt)\n",
    "    \n",
    "    emb_tgt = self.emb_dec(tgt)\n",
    "    \n",
    "    h_tilde = []\n",
    "    h_t_tilde = None\n",
    "    decoder_hidden = h_0_tgt\n",
    "    \n",
    "    for t in range(tgt.size(1)):\n",
    "        emb_t = emb_tgt[:, t, :].unsqueeze(1)\n",
    "        \n",
    "        decoder_output, decoder_hidden = self.decoder(emb_t,\n",
    "                                                      h_t_tilde,\n",
    "                                                      decoder_hidden\n",
    "                                                      )\n",
    "        \n",
    "        context_vector = self.attn(h_src, decoder_output, mask)\n",
    "        \n",
    "        h_t_tilde = self.tanh(self.concat(torch.cat([decoder_output,\n",
    "                                                     context_vector\n",
    "                                                     ], dim=-1)))\n",
    "        \n",
    "        h_tilde += [h_t_tilde]\n",
    "        \n",
    "    h_tilde = torch.cat(h_tilde, dim=1)\n",
    "    \n",
    "    y_hat = self.generator(h_tilde)\n",
    "    \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.5 자귀회귀 속성과 teacher forcing 훈련 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seq2seq의 훈련과 추론은 다르다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.5.1 자기회귀 속성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 자기회귀(autogressive): 과거 자신의 값을 참조하여 현재의 값을 추론하는 특징\n",
    "\n",
    "▶ 신경망 기계번역 수식\n",
    "$$\\hat{Y} = \\argmax_{Y \\in \\mathcal{Y}}P(Y|X) = \\argmax_{Y \\in \\mathcal{Y}}\\prod_{i=1}^nP(y_i|X, \\hat{y}_{<i})$$ \n",
    "$$or$$\n",
    "$$\\hat{y}_t = \\argmax_{Y \\in \\mathcal{Y}}P(y_t|X,\\hat{y}_{<t};\\theta)$$\n",
    "\n",
    "학습 과정에서는 이미 정답을 알고 있고, 예측값과 정답과의 차이를 통해 학습하므로 자기회귀 속성을 유지할 수 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.5.2 teachar forcing 훈련 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://blobscdn.gitbook.com/v0/b/gitbook-28427.appspot.com/o/assets%2F-LFzjkZt6ljMBd4YGVCn%2F-LX4NCwvtTXyg_vzXhF0%2F-LX4NFdMA7NCZp2QYb4z%2F10-05-01.png?generation=1548425965734583&alt=media\" width=\"80%\">\n",
    "\n",
    "훈련할 때는 이전 time-step의 출력을 현재 time-step의 입력으로 넣어줄 수 없다. 하지만 추론할 때는 정답을 모르기 때문에 이전 time-step에서 나온 예측값을 입력으로 넣어준다. 이렇게 훈련하는 방식을 **teacher forcing**이라고 한다.\n",
    "\n",
    "훈련할 때는 입력값이 정해져 있으므로 input feeding이 없는 디코더는 모든 time-step을 한번에 수행할 수 있다.\n",
    "\n",
    "$$H_{tgt} = RNN_{dec}(emb_{dec}([BOS;Y[:-1]]),h_n^{src})$$\n",
    "\n",
    "input feeding은 이전 time-step의 softmax 이전 계층의 값을 단어 임베딩 벡터와 함께 받아야하므로 모든 time-step을 한번에 처리할 수 없다.\n",
    "\n",
    "$$h_t^{tgt} = RNN_{dec}([emb_{tgt}(y_{t-1});\\tilde{h}_{t-1}^{tgt})$$\n",
    "\n",
    "언어 모델의 경우 퍼플렉서티가 문장의 확률과 직접적으로 연관이 있기 때문에 문제가 별로되지 않지만, 기계번역에서는 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.6 탐색(추론)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X만 추어진 상태에서 추론하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.6.1 샘플링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예측값을 softmax 계층의 확률 분포대로 샘플링\n",
    "- 최종적으로 EOS가 나올 때까지\n",
    "- 동일 입력에서 매번 다른 출력 결과 나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.6.2 탐욕 탐색 알고리즘 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "소프트맥스 계층에서 가장 확률값이 큰 인덱스를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.6.3 파이토치 예제코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(self, src, is_greedy=True, max_length=255):\n",
    "    mask, x_length = None, None\n",
    "    \n",
    "    if isinstance(src, tuple):\n",
    "        x, x_length = src\n",
    "        mask = self.generate_mask(x, x_length)\n",
    "    else:\n",
    "        x = src\n",
    "    batch_size = x.size(0)\n",
    "    \n",
    "    emb_src = self.emb_src(x)\n",
    "    h_src, h_0_tgt = self.encoder((emb_src, x_length))\n",
    "    h_0_tgt, c_0_tgt = h_0_tgt\n",
    "    h_0_tgt = h_0_tgt.transpose(0, 1).contiguous().view(batch_size,\n",
    "                                                        -1,\n",
    "                                                        self.hidden_size\n",
    "                                                        ).transpose(0, 1).contiguous()\n",
    "    c_0_tgt = c_0_tgt.transpose(0, 1).contiguous().view(batch_size,\n",
    "                                                        -1,\n",
    "                                                        self.hidden_size\n",
    "                                                        ).transpose(0, 1).contiguous()\n",
    "    h_0_tgt = (h_0_tgt, c_0_tgt)\n",
    "    \n",
    "    y = x.new(batch_size, 1).zero_() + data_loader.BOS\n",
    "    is_undone = x.new_ones(batch_size, 1).float()\n",
    "    decoder_hidden = h_0_tgt\n",
    "    h_t_tilde, y_hats, indice = None, [], []\n",
    "    \n",
    "    while is_undone.sum() > 0 and len(indice) < max_length:\n",
    "        emb_t = self.emb_dec(y)\n",
    "        \n",
    "        decoder_output, decoder_hidden = self.decoder(emb_t,\n",
    "                                                      h_t_tilde,\n",
    "                                                      decoder_hidden\n",
    "                                                      )\n",
    "        context_vector = self.attn(h_src, decoder_output, mask)\n",
    "        h_t_tilde = self.tanh(self.concat(torch.cat([decoder_output,\n",
    "                                                     context_vector\n",
    "                                                     ], dim=-1)))\n",
    "        y_hat = self.generator(h_t_tilde)\n",
    "        y_hats += [y_hat]\n",
    "        \n",
    "        if is_greedy:\n",
    "            y = torch.toqk(y_hat, 1, dim=-1)[1].squeez(-1)\n",
    "        else:\n",
    "            y = torch.multinomial(y_hat.exp().view(batch_size, -1), 1)\n",
    "            \n",
    "        y = y.masked_fill_((1. - is_undone).byte(), data_loader.PAD)\n",
    "        is_undone = is_undone * torch.ne(y, data_loader.EOS).float()\n",
    "        indice += [y]\n",
    "    \n",
    "    y_hats = torch.cat(y_hats, dim=1)\n",
    "    indice = torch.cat(indice, dim=-1)\n",
    "    \n",
    "    return y_hats, indice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.6.4 빔서치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- k개의 후보를 더 추적해서 최적 해에 좀 더 가까워지도록\n",
    "- k x |V| 개의 softmax 결과 중 최고 누적확률 k개를 뽑아 다음 time-step에 넘김\n",
    "    - 현재 time-step까지의 로그 확률에 대한 합 추적하고 있어야 함\n",
    "    - 이전 time-step에서 뽑인 k개에 대해 게산한 현재 time-step의 모든 결과물 중에서 최고 누적확률 k개를 다시 뽑는다.\n",
    "- k개의 미니배치를 만들어 수행하면 병렬 처리 가능\n",
    "- 보통 빔 크기는 10 이하\n",
    "\n",
    "#### 구현 관점에서 바라보기\n",
    "\n",
    "- EOS가 k개 나올 때까지 수행\n",
    "\n",
    "#### 길이 패널티\n",
    "\n",
    "- 현재 time-step까지의 확률의 모든 곱으로 구해지므로 문장이 길어질수록 확률이 낮아지는 단점\n",
    "- 예측한 문장의 길이에 따른 페널티를 주어 짧은 문장이 긴 문장을 제치고 선택되는 문제 방지\n",
    "\n",
    "$$log \\tilde P(\\hat Y|X) = logP(\\hat Y|X) \\times penalty$$\n",
    "$$penalty = \\frac {(1+length)^\\alpha} {(1 + \\beta)^\\alpha}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26758052058674353\n",
      "0.43527528164806206\n",
      "0.6147386076544852\n",
      "0.8034937533355226\n",
      "1.0\n",
      "1.203195357557136\n",
      "1.4122984547317496\n",
      "1.6267076567965477\n",
      "1.8459439054138165\n"
     ]
    }
   ],
   "source": [
    "alpha = 1.2\n",
    "beta = 5\n",
    "\n",
    "for l in range(1, 10):\n",
    "    penalty = ((1 + l)**alpha)/((1 + beta)**alpha)\n",
    "    print(penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.6.5 파이토치 예제 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SingleBeamSearchSpace 클래스\n",
    "\n",
    "#### 클래스 선언 및 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH_PENALTY = 1.2\n",
    "MIN_LENGTH = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleBeamSearchSpace():\n",
    "    \n",
    "    def __init__(self,\n",
    "                 hidden,\n",
    "                 h_t_tilde=None,\n",
    "                 beam_size=5,\n",
    "                 max_length=255):\n",
    "        self.beam_size = beam_size\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        super(SingleBeamSearchSpace, self).__init__()\n",
    "        \n",
    "        self.device = hidden[0].device\n",
    "        self.word_indice = [torch.LongTensor(beam_size).zero_().to(self.device) + data_loader.BOS]\n",
    "        self.prev_beam_indice = [torch.LongTensor(beam_size).zero_().to(self.device) - 1]\n",
    "        self.cumulative_probs = [torch.FloatTensor([.0] + [-float('inf')] * (beam_size - 1)).to(self.device)]\n",
    "        self.masks = [torch.ByteTensor(beam_size).zero_().to(self.device)]\n",
    "        \n",
    "        self.prev_hidden = torch.cat([hidden[0]] * beam_size, dim=1)\n",
    "        self.prev_cell = torch.cat([hidden[1]] * beam_size, dim=1)\n",
    "        \n",
    "        self.prev_h_t_tilde = torch.cat([h_t_tilde] * beam_size,\n",
    "                                        dim=0\n",
    "                                        ) if h_t_tilde is not None else None\n",
    "        \n",
    "        self.current_time_step = 0\n",
    "        self.done_cnt = 0\n",
    "        \n",
    "    # 길이 페널티 구현\n",
    "    def get_length_penalty(self,\n",
    "                           length,\n",
    "                           alpha=LENGTH_PENALTY,\n",
    "                           min_length=MIN_LENGTH\n",
    "                           ):\n",
    "        p = (1 + length) ** alpha / (1 + min_length) ** alpha\n",
    "        \n",
    "        return p\n",
    "    \n",
    "    # 디코딩 작업 종료 체크\n",
    "    def is_done(self):\n",
    "        if self.don_cnt >= self.beam_size:\n",
    "            return 1\n",
    "        return 0\n",
    "    \n",
    "    # 가짜 미니배치의 일부 만들기\n",
    "    def get_batch(self):\n",
    "        y_hat = self.word_indice[-1].unsqueeze(-1)\n",
    "        hidden = (self.prev_hidden, self.prev_call)\n",
    "        h_t_tilde = self.prev_h_t_tilde\n",
    "        \n",
    "        return y_hat, hidden, h_t_tilde\n",
    "    \n",
    "    # 최고 누적확률 k개 고르기\n",
    "    def collect_result(self, y_hat, hidden, h_t_tilde):\n",
    "        output_size = y_hat.size(-1)\n",
    "        \n",
    "        self.current_time_step += 1\n",
    "        cumulative_prob = y_hat + \\\n",
    "            self.cumulative_probs[-1].masked_fill_(self.masks[-1], -float('inf')) \\\n",
    "            .view(-1, 1, 1).expand(self.beam_size, 1, output_size)\n",
    "        top_log_prob, top_indice = torch.topk(cumulative_prob.view(-1),\n",
    "                                              self.beam_size,\n",
    "                                              dim=-1\n",
    "                                              )\n",
    "        \n",
    "        self.word_indice += [top_indice.fmod(output_size)]\n",
    "        self.prev_beam_indice += [top_indice.div(output_size).long()]\n",
    "        \n",
    "        self.cumulative_probs += [top_log_prob]\n",
    "        self.masks += [torch.eq(self.word_indice[-1],\n",
    "                                data_loader.EOS)]\n",
    "        self.done_cnt += self.masks[-1].float().sum()\n",
    "        \n",
    "        self.prev_hidden = torch.index_select(hidden[0],\n",
    "                                              dim=1,\n",
    "                                              index=self.prev_beam_indice[-1]\n",
    "                                              ).contiguous()\n",
    "        self.prev_cell = torch.index_select(hidden[1],\n",
    "                                            dim=1,\n",
    "                                            index=self.prev_beam_indice[-1]\n",
    "                                            ).contiguous()\n",
    "        self.prev_h_t_tilde = torch.index_select(h_t_tilde,\n",
    "                                                 dim=0,\n",
    "                                                 index=self.prev_beam_indice[-1]\n",
    "                                                 ).contiguous()\n",
    "        \n",
    "    # 결괏값 정리\n",
    "    def get_n_best(self, n=1):\n",
    "        sentences, probs, founds = [], [], []\n",
    "        \n",
    "        for t in range(len(self.word_indice)):\n",
    "            for b in range(self.beam_size):\n",
    "                if self.masks[t][b] == 1:\n",
    "                    probs += [self.cumulative_probs[t][b] / self.get_length_penalty(t)]\n",
    "                    founds += [(t, b)]\n",
    "        \n",
    "        for b in range(self.beam_size):\n",
    "            if self.cumulative_probs[-1][b] != -float('inf'):\n",
    "                if not (len(self.cumulative_probs) - 1, b) in founds:\n",
    "                    probs += [self.cumulative_probs[-1][b]]\n",
    "                    founds += [(t, b)]\n",
    "                    \n",
    "        sorted_founds_with_probs = sorted(zip(founds, probs),\n",
    "                                          key=itemgetter(1),\n",
    "                                          reverse=True\n",
    "                                          )[:n]\n",
    "        prob = []\n",
    "        \n",
    "        for (end_index, b), prob in sorted_founds_with_probs:\n",
    "            sentence = []\n",
    "            for t in range(end_index, 0, -1):\n",
    "                sentence = [self.word_indice[t][b]] + sentence\n",
    "                b = self.prev_beam_indice[t][b]\n",
    "                \n",
    "            sentences += [sentence]\n",
    "            probs += [prob]\n",
    "            \n",
    "        return sentences, probs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 병렬 빔서치 수행 함수\n",
    "def batch_beam_search(self, src, beam_size=5, max_length=255, n_best=1):\n",
    "    mask, x_length = None, None\n",
    "    \n",
    "    if isinstance(src, tuple):\n",
    "        x, x_length = src\n",
    "        mask = self.generate_mask(x, x_length)\n",
    "    else:\n",
    "        x = src\n",
    "    batch_size = x.size(0)\n",
    "    \n",
    "    emb_src = self.emb_src(x)\n",
    "    h_src, h_0_tgt = self.encoder((emb_src, x_length))\n",
    "    h_0_tgt, c_0_tgt = h_0_tgt\n",
    "    h_0_tgt = h_0_tgt.transpose(0, 1).contiguous().view(batch_size,\n",
    "                                                        -1,\n",
    "                                                        self.hidden_size\n",
    "                                                        ).transpose(0, 1).contiguous()\n",
    "    c_0_tgt = c_0_tgt.transpose(0, 1).contiguous().view(batch_size,\n",
    "                                                        -1,\n",
    "                                                        self.hidden_size\n",
    "                                                        ).transpose(0, 1).contiguous()\n",
    "    \n",
    "    h_0_tgt = (h_0_tgt, c_0_tgt)\n",
    "    \n",
    "    spaces = [SingleBeamSearchSpace((h_0_tgt[0][:, i, :].unsqueeze(1),\n",
    "                                     h_0_tgt[1][:, i, :].unsqueeze(1)\n",
    "                                     ),\n",
    "                                    None,\n",
    "                                    beam_size,\n",
    "                                    max_length=max_length\n",
    "                                    ) for i in range(batch_size)]\n",
    "    done_cnt = [space.is_done() for space in spaces]\n",
    "    \n",
    "    length = 0\n",
    "    \n",
    "    while sum(done_cnt) < batch_size and length <= max_length:\n",
    "        fab_input, fab_hidden, fab_cell, fab_h_t_tilde = [], [], [], []\n",
    "        fab_h_src, fab_mask = [], []\n",
    "        \n",
    "        for i, space in enumerate(spaces):\n",
    "            if space.is_done() == 0:\n",
    "                y_hat_, (hidden_, cell_), h_t_tilde_ = space.get_batch()\n",
    "                fab_input += [y_hat_]\n",
    "                fab_hidden += [hidden_]\n",
    "                fab_cell += [cell_]\n",
    "                if h_t_tilde_ is not None:\n",
    "                    fab_h_t_tilde += [h_t_tilde_]\n",
    "                else:\n",
    "                    fab_h_t_tilde = None\n",
    "                    \n",
    "                fab_h_src += [h_src[i, :, :]] * beam_size\n",
    "                fab_mask += [mask[i, :]] * beam_size\n",
    "            \n",
    "            fab_input = torch.cat(fab_input, dim=0)\n",
    "            fab_hidden = torch.cat(fab_hidden, dim=1)\n",
    "            fab_cell = torch.cat(fab_cell, dim=1)\n",
    "            if fab_h_t_tilde is not None:\n",
    "                fab_h_t_tilde = torch.cat(fab_h_t_tilde, dim=0)\n",
    "            fab_h_src = torch.stack(fab_h_src)\n",
    "            fab_mask = torch.stack(fab_mask)\n",
    "            \n",
    "            emb_t = self.emb_dec(fab_input)\n",
    "            \n",
    "            fab_decoder_output, (fab_hidden, fab_cell) = self.decoder(emb_t,\n",
    "                                                                      fab_h_t_tilde,\n",
    "                                                                      (fab_hidden, fab_cell))\n",
    "            context_vector = self.attn(fab_h_src, fab_decoder_output, fab_mask)\n",
    "            fab_h_t_tilde = self.tanh(self.concat(torch.cat([fab_decoder_output,\n",
    "                                                             context_vector\n",
    "                                                             ], dim=-1)))\n",
    "            y_hat = self.generator(fab_h_t_tilde)\n",
    "            \n",
    "            cnt = 0\n",
    "            for space in spaces:\n",
    "                if space.is_done() == 0:\n",
    "                    from_index = cnt * beam_size\n",
    "                    to_index = from_index + beam_size\n",
    "                    \n",
    "                    space.collect_result(y_hat[from_index:to_index],\n",
    "                                         (fab_hidden[:, from_index:to_index, :],\n",
    "                                          fab_cell[:, from_index:to_index, :]\n",
    "                                          ),\n",
    "                                         fab_h_t_tilde[from_index:to_index])\n",
    "                    cnt += 1\n",
    "                \n",
    "            done_cnt = [space.is_done() for space in spaces]\n",
    "            length += 1\n",
    "        \n",
    "        batch_sentences = []\n",
    "        batch_probs = []\n",
    "        \n",
    "        for i, space in enumerate(space):\n",
    "            sentences, probs = space.get_n_best(n_best)\n",
    "            \n",
    "            batch_sentences += [sentences]\n",
    "            batch_probs += [probs]\n",
    "            \n",
    "        return batch_sentences, batch_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.7 성능 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.7.1 정성적 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 사람이 블라인드 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.7.2 정량적 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PPL\n",
    "\n",
    "- 신경망 기계번역도 조건부 언어모델이므로 퍼플렉서티를 통해 측정 가능\n",
    "- 교차 엔트로피 손실값에 exp로 구함\n",
    "\n",
    "#### BLEU\n",
    "\n",
    "- PPL이 실제 번역기 성능과 완벽한 비례 X\n",
    "- 정답 문장과 예측 문장 사이에 일치하는 n-gram 개수의 비율의 기하평균에 따라 계산\n",
    "\n",
    "$$BLEU = brevity-penalty * \\prod_{n=1}^N p_n^{w_n}$$\n",
    "$$brevity-penalty = min(1, \\frac {|prediction|} {|reference|})$$\n",
    "$$p_n \\ is \\ precision \\ of \\ n-gram \\ and \\ w_n=(\\frac 1 2)^n$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8408964152537145"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5**0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
