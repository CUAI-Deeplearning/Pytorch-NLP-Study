{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_sentence_order.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO/zkDlivGDQwiOnn7UbjFK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CUAI-Deeplearning/Pytorch-NLP-Study/blob/beomjin/BERT_sentence_order.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CekWH1YSzFKm",
        "colab_type": "text"
      },
      "source": [
        "# BERT \n",
        "## - Sentence Order Finding\n",
        "\n",
        "질문 : BERT로 수능 영어 지문 순서를 맞출 수 있는가?\n",
        "\n",
        "대답 : Yes!\n",
        "\n",
        "Bert input으로  **text_A , text_B, label** 3 가지를 넣을 수 있다.\n",
        "\n",
        "따라서 지문들에 대한 경우의 수를 생각해, 가장 확률이 높은 경우를 선택하면 됩니다. \n",
        "\n",
        " <br/> \n",
        "  ex) A, B, C 세 개의 지문이 있을 때,\n",
        "\n",
        " start - A - B - C  == sum(\\[start-A, A-B, B-C])\n",
        "\n",
        " start - A - C - B  == sum(\\[start-A, A-C, B-C])\n",
        "\n",
        "## BERT로 구해야 하는 경우는 총 9 가지\n",
        "임의의 S에 대하여\n",
        "* start -> S  = 3 가지\n",
        "* S1 -> S2   = 3*2 가지 \n",
        "\n",
        "\n",
        "<br/>\n",
        "<img src=\"https://gluon-nlp.mxnet.io/_images/bert-sentence-pair.png\"\n",
        "     style=\"float: left; margin-right: 10px;\" width=500; height=400; />\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aH2HdGKyqzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 예시\n",
        "ANSWER  = [3,2,1]\n",
        "\n",
        "start = \"Movies may be said to support the dominant culture and to serve as a means for its reproduction over time.\"\n",
        "\n",
        "sent1 = \"The bad guys are usually punished; the romantic couple almost always find each other despite the obstacles and difficulties they encounter on the path to true love; and the way we wish the world to be is how, in the movies, it more often than not winds up being. No doubt it is this utopian aspect of movies that accounts for why we enjoy them so much.\"\n",
        "sent2 = \"The simple answer to this question is that movies do more than present two-hour civics lessons or editorials on responsible behavior. They also tell stories that, in the end, we find satisfying.\"\n",
        "sent3 = \"But one may ask why audiences would find such movies enjoyable if all they do is give cultural directives and prescriptions for proper living. Most of us would likely grow tired of such didactic movies and would probably come to see them as propaganda, similar to the cultural artwork that was common in the Soviet Union and other autocratic societies.\"\n",
        "\n",
        "Bert에 의해서 모든 경우의 수에 대하여 3, 2 ,1 로 문장을 선택했을 때, 확률이 최대가 나오게 한다."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kJJ2haH0h8-",
        "colab_type": "text"
      },
      "source": [
        "# Code\n",
        "\n",
        "1. Bert 를 import 한다\n",
        "2. Stanford lmdb 영화 감성 분석 Sentence를 활용해서 자연스러운 문장을 고른다\n",
        "3. 진짜 순차적인 문장은 1(Real), 문장 순서를 임의로 섞어 가짜 문장을 만들어 0(Fake)로 레이블 한다.\n",
        "4. 훈련을 진행하고 Prediction을 한다. \n",
        "\n",
        "* Test도 만들고 싶지만 패스"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoXKVwJ4p6rH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "12dc2f9a-d12a-4bdc-fe9d-749d0c77eada"
      },
      "source": [
        "# 1. BERT 깔기\n",
        "!pip install bert-tensorflow"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\r\u001b[K     |████▉                           | 10kB 19.5MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 40kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 2.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MLfWYcnowU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2. 라이브러리 임포트 \n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from datetime import datetime\n",
        "\n",
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEhdH0FBzINJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3. lmdb 데이터를 불러오기 위한 함수들\n",
        "\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import re\n",
        "\n",
        "# Load all files from a directory in a DataFrame.\n",
        "def load_directory_data(directory):\n",
        "  data = {}\n",
        "  data[\"sentence\"] = []\n",
        "  data[\"sentiment\"] = []\n",
        "  for file_path in os.listdir(directory):\n",
        "    with tf.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
        "      data[\"sentence\"].append(f.read())\n",
        "      data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
        "  return pd.DataFrame.from_dict(data)\n",
        "\n",
        "# Merge positive and negative examples, add a polarity column and shuffle.\n",
        "def load_dataset(directory):\n",
        "  pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n",
        "  neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n",
        "  pos_df[\"polarity\"] = 1\n",
        "  neg_df[\"polarity\"] = 0\n",
        "  return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Download and process the dataset files.\n",
        "def download_and_load_datasets(force_download=False):\n",
        "  dataset = tf.keras.utils.get_file(\n",
        "      fname=\"aclImdb.tar.gz\", \n",
        "      origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
        "      extract=True)\n",
        "  \n",
        "  train_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                       \"aclImdb\", \"train\"))\n",
        "  test_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                      \"aclImdb\", \"test\"))\n",
        "  \n",
        "  return train_df, test_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfdbpEeuosN1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "57981884-bb81-4b38-969e-11b4dec26713"
      },
      "source": [
        "# 4. Train, Test 받기 \n",
        "train, test = download_and_load_datasets()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8iUAUTlqWVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 5. sampling 을 통해서 진행 (기존 데이터를 섞기 위함인데 우리는 새로운 데이터를 만들기 때문에 필요없다. 다시 sampling 해야 함.)\n",
        "\n",
        "data = train.sample(10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVGXxIzUsSZv",
        "colab_type": "text"
      },
      "source": [
        "Sentence 를 두 개로 분해하기\n",
        "\n",
        "* sentenceA --> 0        <=  len(sentenceA)  < half len\n",
        "\n",
        "* sentenceB --> half len <   len(sentenceB)  < len  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFC7lmW9qsPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 6. BERT 에 COLUMN 명을 알려주기 위한 정의\n",
        "\n",
        "FIRST_COLUMN = 'sentenceA'\n",
        "SECOND_COLUMN = 'sentenceB'\n",
        "LABEL_COLUMN = 'pair'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6mijM59s9Gl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 7. 기존 BERT처리에는 없는 새로운 데이터를 만들기 위한 코드\n",
        "# Fake는 아직 구현 안됨.\n",
        "data[FIRST_COLUMN] = data['sentence'].apply(lambda x : x[: x.find('. ', 0)])\n",
        "data[SECOND_COLUMN] = data['sentence'].apply(lambda x : x[ x.find('. ', 0)+1 : x.find('. ', x.find('. ')+1)] )\n",
        "data[LABEL_COLUMN] = 1\n",
        "data.drop(['sentence','sentiment', 'polarity'], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1D7mTSgMt9cb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f283da20-fd8d-42dc-81e0-779fd24a72f8"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentenceA</th>\n",
              "      <th>sentenceB</th>\n",
              "      <th>pair</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8083</th>\n",
              "      <td>Despite being a sequel to the more potent orig...</td>\n",
              "      <td>There are some pretty darn funny sex scenes w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15903</th>\n",
              "      <td>The clichéd Polynesian males drink, fight and ...</td>\n",
              "      <td>Real life Polynesians are much funnier than t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5616</th>\n",
              "      <td>Although in some aspects Seven Pounds is solid...</td>\n",
              "      <td>The movie becomes more and more sappy and man...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11903</th>\n",
              "      <td>What ever possessed Martin Scorcese to remake ...</td>\n",
              "      <td>Scorcese especially)- attitudes that compel w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1125</th>\n",
              "      <td>Despite an overall pleasing plot and expensive...</td>\n",
              "      <td>Where were the Japanese wardrobe and cultural...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentenceA  ... pair\n",
              "8083   Despite being a sequel to the more potent orig...  ...    1\n",
              "15903  The clichéd Polynesian males drink, fight and ...  ...    1\n",
              "5616   Although in some aspects Seven Pounds is solid...  ...    1\n",
              "11903  What ever possessed Martin Scorcese to remake ...  ...    1\n",
              "1125   Despite an overall pleasing plot and expensive...  ...    1\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDv1DJIHv7wv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "outputId": "5eac5ed1-15be-4732-9d09-4bd752d52319"
      },
      "source": [
        "# 8. 단어 수를 보기 위한 Plot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f, ax = plt.subplots(1,1, figsize=(18,8))\n",
        "\n",
        "A = data.sentenceA.apply(lambda x : len(x.split()))\n",
        "B = data.sentenceB.apply(lambda x : len(x.split()))\n",
        "\n",
        "pd.DataFrame({'A':A, 'B':B}).plot.scatter(x='A', y='B', c='DarkBlue', ax=ax)\n",
        "\n",
        "ax.set_title('Sentence A vs Sentence B')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Sentence A vs Sentence B')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABCkAAAHwCAYAAACL/zUnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdfXzcVZ3//fcnN9NOLS0Is2wtMMNv\nxTWIPyikLYh7XaIpQdYbxB9oVhHsPK5GV7B2vcPqbxGxLLursnjJauMVBF0dlioKihKoVl1YoUlp\ndcEodnUK9FfKWCBQM+0kmXP9Md9JZ5KZZJLMzXcmr+fjkQfJ+d7MmUka5rxzzueYc04AAAAAAAC1\n1lTrDgAAAAAAAEiEFAAAAAAAwCcIKQAAAAAAgC8QUgAAAAAAAF8gpAAAAAAAAL5ASAEAAAAAAHyB\nkAIAAAAAAPgCIQUAAFVkZq81s/80syEze9bMHjSzlWW47xVm9kA5+lgJZvZTM3vOzBZU4bECZvZ5\nM3vKzA6aWdzM/qVM946bWUc57lUu3vd+zHuuB83s92b2/lr3CwCA2SCkAACgSsxsiaQfSPp/Jb1U\n0nJJ10o6XMt+VZqZRST9lSQn6S1VeMhPSGqXtErSUZJeJ+mRKjxuLf3CObfYObdY0tsl/ZOZrah1\npwAAmClCCgAAqucVkuSciznnxpxzSefcfc65X2VPMLO1ZjbozTroM7NwzjFnZu8zs9+Z2fNmdrNl\ntEn6iqRzvL+kP++dv8DMPmdmT5jZfjP7ipkFvWOv82YafNjMnjGzfWb23pzHCnqzEfZ4sz4eyLn2\nbG82yPNm9ksze900z/s9kh6SdKuky4udZGbvMLOBCW0bzOxu7/MLzezXZvaime01s48UudVKSd91\nzv0flxF3zn09554vM7PvmFnCzP5gZh/MOfZpM7vDzL7uPc5jZtbuHfuGpJMkfd97nT823evhzSC5\nzpsx86KZ3Wdmx+Ucf23OtU+a2RVee9Hv3XScczslDUpqK+V8AAD8hJACAIDqeVzSmJndZmZvNLNj\ncg+a2VslbZR0saSQpP+QFJtwjzcpMwj/n5IuldTpnBuU9D4d+Wv60d65NygTjJwh6eXKzNz4+5x7\n/bmkpV57VNLNOX36nKSzJL1GmVkfH5OUNrPlku6R9Fmv/SOSvmNmoSme93skfdP76DSz44uc931J\nf2lmp+S0/Y2kb3mf90rqds4dJek0ST8pcp+HJP2dmf2tmb3azCx7wMyavMf5pfe83yDpQ2bWmXP9\nWyTdLuloSXdL+pIkOecuk/SEpDd7r/M/lfh6/I2k90r6M0kB7xx5AdSPlJlZE1Lm+7TLu2a6711R\n3vKhV0gamO5cAAD8hpACAIAqcc69IOm1yix7+KqkhJndnTNof5+kf3DODTrnRiVdL+mM3NkUkm5w\nzj3vnHtC0jZlBrGTeAPzdZI2OOeedc696N3vnTmnjUj6jHNuxDn3Q0kHlQkJmiStlbTeObfXm/Xx\nn865w5LeLemHzrkfOufSzrn7lRkMX1ikH6+VFJZ0h3Nuh6T/VmbQXuj1GZZ0l6Qu79pTJL1SmaAg\n299TzWyJc+4551yxJRz/IOkfJb3L69teM8vO4FgpKeSc+4xzLuWc+70y34vc1+UB7/mNSfqGpNOL\nPI5KfD2+5px73DmXlHSHjnzP/kbSVm9mzYhz7oBzbleJ37uJzvZmY7woabvX799NcT4AAL5ESAEA\nQBV5AcQVzrkTlJkN8DJJ2aKOYUk3eYPN5yU9K8mU+St61tM5nw9LWlzkoUKSFknakXO/e732rANe\nGDLxfsdJWqhMoDBRWNIl2Xt6932tpGVF+nG5pPucc3/0vv6Wpljy4R3v8j7/G0nf88ILKVNr4UJJ\ne8zsZ2Z2TqEbeKHKzc65c5WZDbFJ0i3espiwpJdN6P9GSbmzOya+xgvNrKVIf0t5PYp9z05U4de4\nlO/dRA855472Zpn8uaRXKRNsAABQV4r9DxcAAFSYc+43ZnarpG6v6UlJm5xz35zN7SZ8/UdJSUmv\ncs7tneG9/ijpkKS/UGZZRK4nJX3DOff/THcTr4bCpZKazSw7UF8g6WgzO905N/HeknS/pJCZnaFM\nWLEhe8A51y/prWbWKulKZWYlnDhVH7zZCzeb2bWSTvX6/wfn3ClTXTfVLSd8XfLrUcCTyhT3nGgu\n3zs55/ab2XckvV+ZIqIAANQNZlIAAFAlZvZKr1DlCd7XJyozEH/IO+Urkj5hZq/yji81s0tKvP1+\nSSeYWUCSnHNpZZYx3Ghmf+bdb/mE2gsFedfeIukLXpHJZjM7xzLbh/6bpDebWafXvtAyRThPKHCr\niySNKRMOnOF9tClTa+M9RR57RNIWSf+sTI2H+72+B8zsXWa21DvnBUnpQvcwsw95fQqaWYu31OMo\nSTuVWQrxopl93DvebGanWenbwO6X9D9yvp7J6zHRNyV1mNmlXj+PNbMz5vK98849VtLbJD1W4nMC\nAMA3CCkAAKieFyWtlvSwmf1JmXDiUUkfliTn3HeVqaVwu5m94B17Y4n3/okyg9KnzSy7tOLjknZL\nesi731ZJf1ni/T4i6b8k9Suz7OQfJTU5556UlC3wmVBmNsBHVfg9xeXK1GN4wjn3dPZDmUKU75pi\nCcW3JHVI2jJhOcplkuLec3mfMjUnChmW9Hlllln8UdIHJL3dOfd7r87Em5QJTP7gHf//lCkgWop/\nkPQpbxnGR2b4euTx6opcqMz3/1llimZm61/M9HuX3dnloDI7eyQkXVXicwIAwDfMuYmzFgEAAAAA\nAKqPmRQAAAAAAMAXCCkAAAAAAIAvEFIAAAAAAABfIKQAAAAAAAC+QEgBAAAAAAB8odjWX3XtuOOO\nc5FIpNbdAAAAAAAAE+zYseOPzrlQoWMNGVJEIhENDAzUuhsAAAAAAGACM9tT7BjLPQAAAAAAgC8Q\nUgAAAAAAAF8gpAAAAAAAAL5ASAEAAAAAAHyBkAIAAAAAAPgCIQUAAAAAAPAFQgoAAAAAAOALhBQA\nAAAAAMAXCCkAAAAAAIAvEFIAAAAAAABfIKQAAAAAAAC+QEgBAAAAAAB8gZACAAAAAAD4AiEFAAAA\nAADwBUIKAAAAAADgC4QUAAAAAADUmURiWP39+5RIDNe6K2VFSAEAAAAAQB2JxQYVDvdozZotCod7\nFIsN1rpLZUNIAQAAAABAnUgkhhWN9imZHNXQUErJ5Kii0b6GmVFBSAEAAAAAQJ2Ix4cUCOQP5Vtb\nmxSPD9WoR+VFSAEAAAAAQJ2IRJYqlUrntY2MpBWJLK1Rj8qLkAIAAAAAgDoRCi1Sb2+ngsEWLVkS\nUDDYot7eToVCi2rdtbJoqXUHAAAAAABA6bq62tTREVY8PqRIZGnDBBQSIQUAAAAAAHUnFFrUUOFE\nFss9AAAAAACALxBSAAAAAAAAXyCkAAAAAAAAvkBIAQAAAAAAfIGQAgAAAAAA+AIhBQAAAAAA8AVC\nCgAAAAAA4AuEFAAAAAAAwBcIKQAAAAAAgC8QUgAAAAAAAF8gpAAAAAAAAL5ASAEAAAAAAHyBkAIA\nAAAAMO8kEsPq79+nRGK41l1BDkIKAAAAAMC8EosNKhzu0Zo1WxQO9ygWG6x1l+AhpAAAAAAAzBuJ\nxLCi0T4lk6MaGkopmRxVNNrHjAqfIKQAAAAAAMwb8fiQAoH8oXBra5Pi8aEa9Qi5CCkAAAAAAPNG\nJLJUqVQ6r21kJK1IZGmNeoRcFQspzGyhmW03s1+a2WNmdq3XfquZ/cHMdnkfZ3jtZmZfNLPdZvYr\nMzsz516Xm9nvvI/LK9VnAAAAAEBjC4UWqbe3U8Fgi5YsCSgYbFFvb6dCoUW17hoktVTw3oclvd45\nd9DMWiU9YGY/8o591Dn37Qnnv1HSKd7HaklflrTazF4q6RpJ7ZKcpB1mdrdz7rkK9h0AAAAA0KC6\nutrU0RFWPD6kSGQpAYWPVCykcM45SQe9L1u9DzfFJW+V9HXvuofM7GgzWybpdZLud849K0lmdr+k\nCyTFKtV3AAAAAEBjC4UWEU74UEVrUphZs5ntkvSMMkHDw96hTd6SjhvNbIHXtlzSkzmXP+W1FWsH\nAAAAAAANpKIhhXNuzDl3hqQTJK0ys9MkfULSKyWtlPRSSR8vx2OZ2TozGzCzgUQiUY5bAgAAAACA\nKqrK7h7OueclbZN0gXNun8s4LOlrklZ5p+2VdGLOZSd4bcXaJz5Gj3Ou3TnXHgqFKvE0AAAAAABA\nBVVyd4+QmR3tfR6UtEbSb7w6EzIzk3SRpEe9S+6W9B5vl4+zJQ055/ZJ6pN0vpkdY2bHSDrfawMA\nAAAAAA2kkrt7LJN0m5k1KxOG3OGc+4GZ/cTMQpJM0i5J7/PO/6GkCyXtljQs6b2S5Jx71syuk9Tv\nnfeZbBFNAAAAAADQOCyzmUZjaW9vdwMDA7XuBgAAAAAAmMDMdjjn2gsdq0pNCgAAAAAAgOkQUgAA\naiKRGFZ//z4lEsO17goAAAB8gpACAFB1sdigwuEerVmzReFwj2KxwVp3CQAAAD5ASAEAqKpEYljR\naJ+SyVENDaWUTI4qGu1jRgUAAAAIKQAA1RWPDykQyP/fT2trk+LxoRr1CAAAAH5BSAEAqKpIZKlS\nqXRe28hIWpHI0hr1CAAAAH5BSAEAqKpQaJF6ezsVDLZoyZKAgsEW9fZ2KhRaVOuuAQAAoMZaat0B\nAMD809XVpo6OsOLxIUUiSwkoAAAAIImQAgBQI6HQIsIJAAAA5GG5BwAAAAAA8AVCCgAAAAAA4AuE\nFAAAAAAAwBcIKQAAAAAAgC8QUgAAAAAAAF8gpAAAAAAAAL5ASAEAAAAAAHyBkAIAAAAAAPgCIQUA\nAAAAAPAFQgoAAAAAAOALhBQAAAAAAMAXCCkAAAAAAIAvEFIAAAAAAABfIKQAAAAAAAC+QEgBAAAA\nAAB8gZACAAAAAAD4AiEFAAAAAADwBUIKAAAAAADgC4QUAAAAAADAFwgpAAAAAACALxBSAAAAAAAA\nXyCkAAAAAAAAvkBIAQAAAAAAfIGQAgAAAAAA+AIhBQAAAAAA8AVCCgAAAAAA4AuEFAAAAAAAwBcI\nKQAAAAAAgC8QUgAAAAAAAF8gpAAAAAAAAL5ASAEAAAAAAHyBkAIAAAAAAPgCIQUAAAAAAPAFQgoA\nAAAAAOALhBQAAAAAAMAXKhZSmNlCM9tuZr80s8fM7Fqv/WQze9jMdpvZv5tZwGtf4H292zseybnX\nJ7z235pZZ6X6DAAAAAAAaqeSMykOS3q9c+50SWdIusDMzpb0j5JudM69XNJzkqLe+VFJz3ntN3rn\nycxOlfROSa+SdIGkfzWz5gr2GwAAAEADSSSG1d+/T4nEcK27AmAaFQspXMZB78tW78NJer2kb3vt\nt0m6yPv8rd7X8o6/wczMa7/dOXfYOfcHSbslrapUvwEAAAA0jlhsUOFwj9as2aJwuEex2GCtuwRg\nChWtSWFmzWa2S9Izku6X9N+SnnfOjXqnPCVpuff5cklPSpJ3fEjSsbntBa7Jfax1ZjZgZgOJRKIS\nTwcAAABAHUkkhhWN9imZHNXQUErJ5Kii0T5mVAA+VtGQwjk35pw7Q9IJysx+eGUFH6vHOdfunGsP\nhUKVehgAAAAAdSIeH1IgkD/kaW1tUjw+VKMeAZhOVXb3cM49L2mbpHMkHW1mLd6hEyTt9T7fK+lE\nSfKOL5V0ILe9wDUAAAAAUFAkslSpVDqvbWQkrUhkaY16BGA6ldzdI2RmR3ufByWtkTSoTFjxv7zT\nLpd0l/f53d7X8o7/xDnnvPZ3ert/nCzpFEnbK9VvAAAAAI0hFFqk3t5OBYMtWrIkoGCwRb29nQqF\nFtW6awCKaJn+lFlbJuk2byeOJkl3OOd+YGa/lnS7mX1W0k5Jvd75vZK+YWa7JT2rzI4ecs49ZmZ3\nSPq1pFFJH3DOjVWw3wAAAAAaRFdXmzo6worHhxSJLCWgAHzOMpMVGkt7e7sbGBiodTcAAAAAAMAE\nZrbDOdde6FhValIAAAAAAABMh5ACAAAAAAD4AiEFAAAAAADwBUIKAAAAAADgC4QUAAAAAADAFwgp\nAAAAAACALxBSAAAAAAAAXyCkAAAAAAAAvkBIAQAAAAAAfIGQAgAAAAAA+AIhBQAAAAAA8AVCCgAA\nAAAA4AuEFAAAAAAAwBcIKQAAAAAAgC8QUgAAAAAAAF8gpAAAAAAAAL5ASAEAAAAAAHyBkAIAAAAA\nAPgCIQUAAAAAAPAFQgoAAAAAAOALhBQAAAAAAMAXCCkAAAAAAIAvEFIAAAAAAABfIKQAAAAAAAC+\nQEgBAAAAAAB8gZACAAAAAAD4AiEFAAAAAADwBUIKAAAAAADgC4QUAAAAAADAFwgpAAAAAACALxBS\nAAAAAAAAXyCkAAAAAAAAvkBIAQAAAAAAfIGQAgAAAAAA+AIhBQAAAAAA8AVCCgAAAAAA4AuEFAAA\nAAAAwBcIKQAAAAAAgC8QUgAAAAAAAF8gpAAAAAAAAL5ASAEAAAAAAHyBkAIAAAAAAPgCIQUAAAAA\nAPCFioUUZnaimW0zs1+b2WNmtt5r/7SZ7TWzXd7HhTnXfMLMdpvZb82sM6f9Aq9tt5ldXak+AwAA\nAACA2mmp4L1HJX3YOfeImR0laYeZ3e8du9E597nck83sVEnvlPQqSS+TtNXMXuEdvlnSGklPSeo3\ns7udc7+uYN8BAAAAAECVVSykcM7tk7TP+/xFMxuUtHyKS94q6Xbn3GFJfzCz3ZJWecd2O+d+L0lm\ndrt3LiEFAAAAAAANpCo1KcwsImmFpIe9pivN7FdmdouZHeO1LZf0ZM5lT3ltxdoBAAAAAEADqXhI\nYWaLJX1H0oeccy9I+rKkv5B0hjIzLT5fpsdZZ2YDZjaQSCTKcUsAAAAAAFBFFQ0pzKxVmYDim865\nOyXJObffOTfmnEtL+qqOLOnYK+nEnMtP8NqKtedxzvU459qdc+2hUKj8TwYAAAAAAFRUJXf3MEm9\nkgadc1/IaV+Wc9rbJD3qfX63pHea2QIzO1nSKZK2S+qXdIqZnWxmAWWKa95dqX4DAAAAAIDaqOTu\nHudKukzSf5nZLq9to6QuMztDkpMUl9QtSc65x8zsDmUKYo5K+oBzbkySzOxKSX2SmiXd4px7rIL9\nBgAAAAAANWDOuVr3oeza29vdwMBArbsBAAAAAAAmMLMdzrn2QseqsrsHAAAAAADAdAgpAAAAAACA\nLxBSAAAAAAAAXyCkAAAAAAAAvkBIAQAAAAAAfIGQAgAAAAAA+AIhBQAAAAAA8AVCCgAAAAAA4AuE\nFAAAAAAAwBcIKQAAAAAAgC8QUgAAAAAAAF8gpAAAAAAAAL5ASAEAAAAAAHyBkAIAAAAAAPgCIQUA\nAAAAAPAFQgoAAAAAAOALhBQAAAAAAMAXCCkAAAAAAIAvEFIAAAAAAABfIKQAAAAAAAC+QEgBAAAA\nAAB8gZACAAAAAAD4AiEFAAAAAADwBUIKAACAeSCRGFZ//z4lEsO17goAAEURUgAAADS4WGxQ4XCP\n1qzZonC4R7HYYK27BABAQYQUAAAADSyRGFY02qdkclRDQyklk6OKRvuYUQEA8CVCCgAAgAYWjw8p\nEMh/y9fa2qR4fKhGPQIAoDhCCgAAgAYWiSxVKpXOaxsZSSsSWVqjHgEAUBwhBQAAQAMLhRapt7dT\nwWCLliwJKBhsUW9vp0KhRbXuGgAAk7TUugMAAACorK6uNnV0hBWPDykSWUpAAQDwLUIKAACAeSAU\nWkQ4AQDwPZZ7AAAAAAAAXyCkQEkSiWH19+9juzIAAAAAQMUQUmBasdigwuEerVmzReFwj2KxwVp3\nCQAAAADQgAgpMKVEYljRaJ+SyVENDaWUTI4qGu1jRgUAAAAAoOwIKTCleHxIgUD+j0lra5Pi8aEa\n9QgAAAAA0KgIKTClSGSpUql0XtvISFqRyNIa9QioHGqvAKgGftcAAFAcIQWmFAotUm9vp4LBFi1Z\nElAw2KLe3k62MEPDofYKgGrgdw0AAFMz51yt+1B27e3tbmBgoNbdaCiJxLDi8SFFIksJKNBwEolh\nhcM9SiZHx9uCwRbt2bOOn3cAc5L7/09J/K4BAECSme1wzrUXOtZS7c6gPoVCi3gDhYaVrb2STB5p\ny9Ze4ecewGzFYoOKRvsUCDQplUpr48bV/K4BAGAahBQA5j1qrwAot9zdsbKhxPXXP6yJM1j5XQMA\nQD5qUgCY96i9AmAuChXCLLY71ic/eTa/awAAmAI1KQDAQ+0VADM1cUlHb2+nurrapqx1I4nfNQCA\neY2aFABQAmqvAJiJQks6otE+dXSEx2doRaN9am1t0shIOm/WBL9rAAAorGLLPczsRDPbZma/NrPH\nzGy91/5SM7vfzH7n/fcYr93M7ItmttvMfmVmZ+bc63Lv/N+Z2eWV6jMAAECpii3piMeHJEldXW3a\ns2edtm69RHv2rFNXV1stugkAQF2p5EyKUUkfds49YmZHSdphZvdLukLSj51zN5jZ1ZKulvRxSW+U\ndIr3sVrSlyWtNrOXSrpGUrsk593nbufccxXsOwAAwJRKKbrLDC0AAGamYjMpnHP7nHOPeJ+/KGlQ\n0nJJb5V0m3fabZIu8j5/q6Svu4yHJB1tZsskdUq63zn3rBdM3C/pgkr1GwAAoBQU3QUAoPyqUpPC\nzCKSVkh6WNLxzrl93qGnJR3vfb5c0pM5lz3ltRVrBwAAqKmurjZ1dIQphAkAQJlUPKQws8WSviPp\nQ865F8xs/JhzzplZWbYXMbN1ktZJ0kknnVSOWwIAAEyLJR0AAJRPxZZ7SJKZtSoTUHzTOXen17zf\nW8Yh77/PeO17JZ2Yc/kJXlux9jzOuR7nXLtzrj0UCpX3iQAAAAAAgIqr5O4eJqlX0qBz7gs5h+6W\nlN2h43JJd+W0v8fb5eNsSUPespA+Seeb2THeTiDne20AAAAAAKCBVHK5x7mSLpP0X2a2y2vbKOkG\nSXeYWVTSHkmXesd+KOlCSbslDUt6ryQ55541s+sk9XvnfcY592wF+w0AAAAAAGrAnCtLSQhfaW9v\ndwMDA7XuBgAAqKFEYpiClgAA+JCZ7XDOtRc6VtGaFAAAALUQiw0qHO7RmjVbFA73KBYbrHWXAABA\nCQgpAABAQ0kkhhWN9imZHNXQUErJ5Kii0T4lEsO17hoAAJgGIQUAAKhbicSw+vv35QUQ8fiQAoH8\ntzitrU2Kx4eq3T0AADBDhBQAAKAuFVvSEYksVSqVzjt3ZCStSGRpLboJAABmgJACAADUnamWdIRC\ni9Tb26lgsEVLlgQUDLaot7eT4pkAANSBSm5BCgAAUBHZJR3J5JG27JKOUGiRurra1NERZncPAADq\nDCEFAACoO6Us6QiFFhFOAABQZ2a83MPMjjMzq0RnAADA/JYthDk4eGBSQcxcLOkAAKAxTTmTwszO\nlnSDpGclXSfpG5KOk9RkZu9xzt1b+S4CAIBGl0gMa/PmXbr++u2SnJLJMQWDmbcpvb2d6upqm3QN\nSzoAAGg80y33+JKkjZKWSvqJpDc65x4ys1dKikkipAAAAHMSiw1q7dp7dejQWF57MjkqSYpG+9TR\nES4YQrCkAwCAxjLdco8W59x9zrktkp52zj0kSc6531S+awAAoNFld+mYGFDkyhbEBAAAjW+6kCK3\nIlVywjFX5r4AAIB5JrtLx1QmFsQEAACNa7rlHqeb2QuSTFLQ+1ze1wsr2jMAANDwCu3SkZVbk4Il\nHQAAzA9ThhTOueZqdQQAAMw/2V06otE+tbY2KZUa0yc/ebbe/vZX6ODBFAUxAQCYZ6abSQEAAFBR\n7NIBAACyCCkAAEDNsUsHAACQpi+cCQAAAAAAUBWEFAAAAAAAwBcIKQAAAAAAgC8QUgAAAAAAAF8g\npAAAAAAAAL5ASAEAAAAAAHyBkAIAAAAAAPgCIQUAAAAAAPAFQgoAAAAAAOALhBQAAAAAAMAXCCkA\nAAAAAIAvEFIAAAAAAABfIKRoAInEsPr79ymRGK51VxoarzMAAAAAVBYhRZ2LxQYVDvdozZotCod7\nFIsN1rpLDalWrzPBCAAAAID5xJxzte5D2bW3t7uBgYFad6PiEolhhcM9SiZHx9uCwRbt2bNOodCi\nGvassdTqdY7FBhWN9ikQaFIqlVZvb6e6utoq9ngA4CeJxLDi8SFFIkv5fxoAAA3GzHY459oLHWMm\nRR2Lx4cUCOR/C1tbmxSPD9WoR42pFq9zIjGsaLRPyeSohoZSSiZHFY32MaMCgKTGn2XFLEEAAOYv\nQoo6FoksVSqVzmsbGUkrEllaox41plq8zgRQAIpp9AE8IS0AAPMbIUUdC4UWqbe3U8Fgi5YsCSgY\nbFFvbyfTYsusFq8zARSAQubDAJ6QFgCA+a2l1h3A3HR1tamjI8y63Qqr9uucDUai0T61tjZpZCRN\nAAVgfACfTB5pyw7gG+X3AyEtAADzGyFFAwiFFjXMm1M/q/brTAAFYKL5MIAnpAUAYH4jpAB8jAAK\nQK75MoAnpAUAYP5iC1IAAOoM23MCAIB6NtUWpMykAACgBuYSNDDLCgAANCp29wAAoMoafRtRAACA\n2SKkAACgiubDNqIAAACzRUgBAEAVZbcRzZXdRhQAAGC+I6QAAKCK5sM2ogAAALNFSAEAQBVltxEN\nBlu0ZElAwWBLQ24jCgAAMBsVCynM7BYze8bMHs1p+7SZ7TWzXd7HhTnHPmFmu83st2bWmdN+gde2\n28yurlR/AQColq6uNu3Zs05bt16iPXvWqaurrdZdAgAA8IVKbkF6q6QvSfr6hPYbnXOfy20ws1Ml\nvVPSqyS9TNJWM3uFd/hmSWskPSWp38zuds79uoL9BgCg4thGFAAAYLKKzaRwzv1c0rMlnv5WSbc7\n5w475/4gabekVd7Hbufc751zKUm3e+cCAFB1icSw+vv3sRMHAABAhdSiJsWVZvYrbznIMV7bcklP\n5pzzlNdWrB0AgKqKxQYVDvdozZotCod7FIsN1rpLAAAADafaIcWXJf2FpDMk7ZP0+XLd2MzWmdmA\nmQ0kEoly3RYAACUSw4pG+5RMjmpoKKVkclTRaB8zKgAAAMqsqiGFc26/c27MOZeW9FVllnNI0l5J\nJ+aceoLXVqy90L17nHPtzjmjkY4AACAASURBVLn2UChU/s4DAOateHxIgUD+/zJbW5sUjw/VqEcA\nAACNqaohhZkty/nybZKyO3/cLemdZrbAzE6WdIqk7ZL6JZ1iZiebWUCZ4pp3V7PPAABEIkuVSqXz\n2kZG0opEltaoRwAAAI2pkluQxiT9QtJfmtlTZhaV9E9m9l9m9itJ50naIEnOucck3SHp15LulfQB\nb8bFqKQrJfVJGpR0h3cuVJ4CbhSBA4DphUKL1NvbqWCwRUuWBBQMtqi3t5PdOQAAAMrMnHO17kPZ\ntbe3u4GBgVp3o6JisUFFo30KBJqUSqXV29uprq62qt8DAOpNIjGseHxIkcjSGYcMc7kWAAAAGWa2\nwznXXvAYIUX9SSSGFQ73KJkcHW8LBlu0Z8+6kt80l+MeAFBvCGcBAABqb6qQohZbkGKOylHAjSJw\nAOaLwcEDuu22R/Xgg3vZoQMAAMDnWmrdAcxcOQq4UQQOwHxw1VVb9aUv7Rr/urXV8o5nw1lmkAEA\nAPgDMynqUDkKuFEEDkCjGxw8kBdQSNLIiJvwNeEsAACAnzCTok51dbWpoyM8pwJu5bgHAPjV9u37\nCra3tjYpGGzRyEiacBYAAMBnCCnqWCi0aM5vrstxDwCopWI7bqxatazg+du2vUOBQBPhLAAAgA+x\n3AMAULdisUGFwz1as2aLwuEexWKD48fa2o7VlVeekXf+lVeeoXPPXa6VK5cRUAAAAPgQW5ACAOpG\n7qwJSSVtpTw4eEDbt+/TqlXL1NZ2bNX7DAAAgHxTbUHKcg9MUmzqNADUUiw2qGi0T4FAk1KptDZu\nXK1AoEnJ5JFzCu3W0dZ2LOEEAABAnSCkQJ6Jg4De3k51dbXVulsA5rlEYljRaJ+SydHxUGLTpodk\nlr+lKLt1AAAA1DdqUmBc7iBgaCilZHJU0WifEonhWncNwDwXjw8pEMj/X1Yg0KyNG1ezlTIAAEAD\nYSYFxmUHAdNNnQaAaotEliqVSue1jYyk1d19urq7T2eJGgAAQINgJgXGFRsEMHUaQK2FQovU29tZ\ncNZEKLSI3ToAAAAaBDMpMC47CIhG+9Ta2qSRkTRTpwH4RldXmzo6wsyaAAAAaGBsQYpJ2N0DQCXw\nuwUAAAASW5BihrLTpwGgXNg5CAAAAKWgJgUAoKLYOQgAAAClIqQAAFRUoe1DszsHAQAAALkIKQAA\nZZFIDKu/f9+kGRLsHAQAAIBSEVIAAOYsFhtUONyjNWu2KBzuUSw2OH5squ1DAQAAgFzs7gEAmJGJ\nu3QkEsMKh3uUTI6OnxMMtmjPnnV5QQS7ewAAAEBidw8AQJkU2qXj5S8/WoFAk5LJI+dla07khhHs\nHAQAAIDpsNwDAFBUbp2JYrt0LF4coOYEAAAAyoKQAgBQ0MQ6E5s3/7LgLh0HD6aoOQEAAICyYLkH\nACBPIjGsnTv3j8+ayC7juP76hzWxjlF2xsTKlcvU0RGm5gQAAADmhJACNUcxPcAfEolhbd78S23a\n9JCamy2vEKaUmTXx0Y+u1PXXP6zW1iaNjKTzZkxQcwIAAABzRUiBmipUhK+rq63W3QLmlUw4sUub\nNj2sQ4fGip43MpJWd/fp6u4+nWARAAAAFUFIgZrJLcKXnU4ejfapoyPMwAeosOwMpkce2a8PfWjb\nlOHES17SqnTaTZo1AQAAAJQbIQVqJh4fKmnbQgDlkRtMbNjwU7W0mF58cWTKaxYubNadd75FK1Yc\nz79LAAAAVBwhBWomElnKtoVAlWSXVpUSTGQtXNisW265QOeff3KFewcAAABksAUpaiYUWsS2hUAV\n5C6tKiWgWLiwWdddd66eeKKbGjEAAACoKmZSoKa6utrYthCosEJLqyY66qiARkbG9MlPnq3u7tP5\ntwgAAICaIKRAzbFtIaphPmx1W+w5FlpaJWWCidHRtG688XU688zjG/q1AQAAQH0gpMCczIeBH+pf\nI291O7EYZqHnmF1aFY32qbW1SSMjBBMAAADwJ3PO1boPZdfe3u4GBgZq3Y26M9PAoZEHfpg5vwZW\nicSwwuEeJZOj423BYIv27Fnnq37OxpFimE168cVU3rFCz9Gv3yMAAADML2a2wznXXugYhTPrXCIx\nrP7+fUokhud0n1hsUOFwj9as2aJwuEex2OC0j5stxDc0lFIyOapotG/O/UB9munPTzVl6zHkym51\nW8/yi2GmJh0v9BxDoUVauXIZAQUAAAB8i5CijpVrYDibwKFRB36YOb8HVo261W2hf4O5GuE5AgAA\nYP4hpKhT5RwYziZwaKSBX7lmo8xXfg+s6nWr20RiWPfd9wfdd98fCv5sFiuGuXhxa908RwAAAGAi\nCmfWqUJbCmYHhjMdmMwmcChUiC87KKqnde/U1Zi7egis6mWr2+y/nZ/97EldffXPNTaWaQ8EmnTr\nrW/M+9ksXAzzPJ155p/5+jkCAAAAU6FwZp0qpRjgTMKC7GA9N3AoZbA+8TEqNeivRPDRyAUVq222\nPz84IvsaptNOhw+PTTpe7GeznkJBAAAAQJq6cCYhRR2bamA4m7BgroOdSg36s8+lqcmUTruyDYD7\n+/dpzZotGho6UnRwyZKAtm69RCtXLpvz/ecbBsszl33NFi8O6KyzvpH3b2eil7ykVdu2XcrPJgAA\nAOreVCEFyz3qWLEp7Ln1KrLLQaLRPnV0hKccPIZCi+Y0uCznEpSsRGJYV1zxo7zlBFdc8aNpn0sp\n6mGZQj2Z68/PfJMbJB46NKamaSoEpdOOn00AAAA0PApn1rlCWwrWqpBhJQb9O3fun3TPVCqtnTv3\nz/qeWfVaUBH1b2Lh28OHx5RMTl7ikdXaavxsAgAAYF5gJkUDqtUMgamKafpVvRRURP168MG9uu++\nuM4/P6Jzz10uqfCso2CwRem0k5l06NCYFi5slnPShg1n6e/+rp2fTQAAAMwLFQspzOwWSW+S9Ixz\n7jSv7aWS/l1SRFJc0qXOuefMzCTdJOlCScOSrnDOPeJdc7mkT3m3/axz7rZK9bneFKsBUMuwoNyD\n/hUrjldrq2lk5EjtlNZW04oVx8+1q+NYpoBKSCSG9eY336mHH35akvSZz/xC559/kvr6Li26fejO\nne/RwYMpLV4c0MGDKYIzAAAAzDsVK5xpZv+XpIOSvp4TUvyTpGedczeY2dWSjnHOfdzMLpR0lTIh\nxWpJNznnVnuhxoCkdklO0g5JZznnnpvqsedD4cxSCmM2SiHDWGxQa9feq+Zm09iY0y23XMDOEfCt\nRGJYmzfv0nXXPVQwiHjggS6de+5ydkQBAADAvFWz3T3MLCLpBzkhxW8lvc45t8/Mlkn6qXPuL81s\ns/d5LPe87IdzrttrzzuvmEYPKebj1pmNErigcWXCiV/qs5/9hQ4fnhxOZP3935+ja689d/wafq4B\nAAAw3/hpd4/jnXP7vM+flpSds79c0pM55z3ltRVrn9cqsYuG37EkA36WnRUx1RaiWeefHxn/nJ9r\nAAAAIF/NCmc655yZlW0ah5mtk7ROkk466aRy3daX2DoTqK3BwQPavn2fVq1apuOOC84goDhpvHhm\nPWHGBwAAAKql2luQ7veWecj77zNe+15JJ+acd4LXVqx9Eudcj3Ou3TnXHgqFyt5xP/Hj1pmJxLD6\n+/cpkRiuWR+Aarjqqq069dSv6Yor7tWpp35NH/jA1klb/uYKBJp08cUv1wMPdKmv79Iq9rQ8YrFB\nhcM9WrNmi8LhHsVig7XuEgAAABpYtWtS/LOkAzmFM1/qnPuYmf21pCt1pHDmF51zq7zCmTsknend\n8hFlCmc+O9XjNnpNiqxK/XVzpvctpYgnUM+y/yZSqbRe+9rJJXEWLGiaVIdiwYImfepT56i7+/S6\nnX0wH+vfAAAAoPJqUpPCzGLKFL48zsyeknSNpBsk3WFmUUl7JGX/rPhDZQKK3cpsQfpeSXLOPWtm\n10nq9877zHQBxXxSifXsMw0cEonh8anu2RoZ0WifOjrCDGJQ1wYHD2jr1j3avfs59fT8SgsWNBdd\n0nHFFafp61//9fhOHRs3rq7rcCJrPta/AQAAQG1VLKRwznUVOfSGAuc6SR8ocp9bJN1Sxq5hguxf\niRcvDsw4cGAQg0aSCSbiuuee36uvb0/esUOHxopet379Wbruutc2XN0G6t8AAACg2mpWOBP+kDtz\n4tChMTU1Wd7x5mabMnBgEINGMDh4QFddtVU//vGT056bnWWUdeWVZ6it7VhJaphwIitb/yYa7Ruf\nJVLr+jcAAABobIQU81ihpRoTHTw4okceeUYrVy4reJxBDOrZD37w3/rwh3+ixx8fKvma5uYmPfDA\nO7R793NatWrZeEDRqLq62tTREW64WSJAKdjZBgCA6qto4cxaaaTCmZV8g9Tfv09r1mzR0FBqyvNK\nKZRX6TdyvFFEub361V/To48emNE1Cxc265ZbLqAwLDAPUBQaAIDKqUnhTMxO7mB869Y9FX2DVGip\nRiFNTVMv+ZDmVsRzugCCN4ooh0RiWNu2PaH9+/+klpamGQUUzc2mT3/6NQ1RDBPA9CgKDQBA7RBS\n+EjuYPzw4TGl006pVHrOb5CKhQC5SzWam02pVOYxR0fzZ9ek065iNSamCyB4o4hy+NzntutjH/u5\nZjJxrKlJuuyyU3Xhhf9D5513Ej9vwDxCUWgAAGqHkMInSqkPMZs3SNOFAF1dbXrhhcNav36bFixo\n0aFDI2pulsa8jQwCgaay1JgoFJSUEkDwRhGzMTh4QNu379OqVcv0+c/3q7f30ZKvPfvsP9eGDe0E\nE8A8RlFoAABqh5DCJwoNxiea6RukUkKARGJYGzb8VIcPj+nw4UwysXBhs771rTfq6KMXaMWK4+c8\nUCsWlJQSQPBGETN18cXf03e/u3tW1/7zP//f+shHVpa5RwDqDUWhAQCoHUIKnyg0GG9tNbW0NE/7\nBqnYco5SQoBC5wQCzTr55KVFd/SYiamCklICCN4oolSDgwf0lrfcqd27S9+p41//9Q168MH/o7PO\n+jO9+92v4ucKwDh2tgEAoDYIKXyi2GB8ujdIUy3nKCUEqPRMhamCkpUrl5UUQMyHN4rV2r2kkXZJ\nyT6XxYsDuuaaB7Vly+Mzuv7KK8/Q+9+/Qu9//4oK9RBAvZtLUWgAADA7hBQ+UmwwXuwNUinLOTZu\nXK1Nmx5SINA8HgJIme1HszuIjI6Ojd+zXDUosqYLQUoNIOrxjWKpgUC1di9ppF1Sss9Fckomx6Y9\nP9df/dXLtHlzp9rajq1M5wAAAADMGiGFz8xkMD7VLIXc7UvNTB/96Ep1d5+urVv3KBzuGR+ojo6O\naWTkyJYHTU2mjo5wyf2dbiBeynKNegwgplNqIFCt3UsaZZeURGJYO3fu19q19+rQodLCibe97eXa\ntOmvxgtpEk4AAAAA/kVIUceKzVJYvDgwaUB6/fUP6+1vf8W0O4iYWck7Z5Q6EJ/rco16W6Iwk0Bg\ntruXzPQ1qeddUhKJYW3b9oTuuef3uuOO36q5uankgOI1r1mmO++8SJIIJwAAAIA6QEhRh3IHqNHo\nafrSl3aNH4tGT9PBg6mCA9Lt2/dNu4NIMjmqxYsDJfVhJn+ZLzRbopSBdilBSLHtTWsVbMwkEJhN\nTZDZLNuot11SsluIJhLDuvrqn49viZsxfUCxcuXxuvHG1+vcc5dXrI8AAAAAyo+Qos5MHKDm1pOQ\npN7eR/W3f7ui4IB01aplk9onWriwWQcPpqbtx2z+Mp8bHOQuR5kqfJguCCk0YM+eV6vaCzMJBGa6\ne8lsl23Uwy4p2aUcX/rSTn3/+78v6Zrs9zgYbJFzTpdf/iqtX38WsyYAAACAOkVIUUcKDVAnam1t\n0sGDqYID0ra2Yye1T6xJYWYl/XV9pn+Zzw0TDh8eUzrtlEqlpxxoTxeEFHo91q69V2Y2p9oLc52F\nMdNAYCbLYeaybMPPu6TEYoO67LJ7JsyYmFow2KLvfe+tOvHEJTp4MOW75wQAAABg5ggp6kihAepE\n2aBg5cplBQekEweq2RkNM/3r+kwG4qWGKxMH2tMFIYVej+Zmk2TT3jvbr4mvT7l2wJhpIFBq8dC5\nLtvwW5HS7OyJd73rHjk3/flZCxc2q7e3U+eff3LlOgcAAACg6ggp6kihAWog0KSmJsvbYjR369Lp\n6kPM5a/rpV47k3BlYj9zg5BUakwbN64eP17o9Rgbc7L8jKLgvQuFER0d4bLugFGJQKAelm1MJRsM\npVJpffWru/Stb/1Gzc02o4DikkteoZtv7qib5wwAAACgdOZmMjqoE+3t7W5gYKDW3aiI7OA6d4Dq\n1yn8WYnEsMLhHiWTo+Ntra2mlpbmvOdRbMZCIjGszZt36frrt0+a4VDo9ZCU17Zx42p1d5+eV1Rz\nYn+ySwcuvfT7Gho6UpNjyZKAtm69RCtXLqvESzNrtSgMOpfHzP0ejo2lp62Nkmvt2tPU2RnR/v1/\nUkdHhHoTAAAAQJ0zsx3OufaCxwgp6s9Ug8XZHpvNeTM5PxYb1Nq196q52TQ25nTLLReUHK4UCxX2\n7Fk3Xpui0O4emzf/Ups2PaQFC5rzgo3+/n1as2bLpDBiy5Y366KL7ir6OPPZbJfBPPjgXn3hC/36\nwQ/+W6nUzH7XvOMdp+iaa15LKAEAAAA0mKlCCpZ71KFiywimGkhu3rxL69dvUyDQpNFRV3SQOdPB\naPb8lpbMcoybbnq9urtPL3iuWaZeRHY5RqnLIaYrFlnsPtdf/7AOHRrToUOZaozZpRvF6jqsWHG8\nb5dS1HJL1dnsKDI4eEBve9t39dvfPj+rx1y79jT19l4w2y4DAAAAqFPMpGgQU802uPPOx/W+923N\nO7/QDIHpZiyU8piS9JWvdKi7+4xZ33cmz63Y9cVmS2SXbhRaJpINY2oZCBRSrmKeszXda5lrcPCA\nurvv03/8x94ZP84115yjk09eqlWrljF7AgAAAGhgzKSYB4rNNti5c7/Wr9826fzmZpu048VMt7eM\nx4fU0tI0qX39+m26+OJXjF8zl20zpdkVi5xuF4ypin76aQeM2cxiKLfpXstEYlh33fU7/cu/7NBj\njz074/ubSV/+cn6wBQAAAGB+IqRoAInEsJ577pAOHx7Lax8ZyQwsA4HmgsdyB5nx+JAWLw7MaHvL\nzOB1bFJ7bgCR7dtcts2UZrel53TBhp/CiGIKBTxNTdLOnfurtv3mVK/l5s27Js3SmUogYPrf//s1\nOu+8k/TII0/r+ONfovPOO8n33wcAAAAA1UFIUedylwKk006traZgsHV8ILlixfE6fHh00nU33XSe\nQqFFk5YSRKOnqbf30ZJmLIRCi3TTTa/X+953f1776GgmgMi99+jomAKBJi1c2DLrWg8zDRXmsr2q\nXxSaxfCnP43qoovuquqyj4mv5eOPP6c3venbuueeeMn3OPPMkO6995Lx78O55y6vUG8BAAAA1Ctq\nUtSR3BkPBw+mtHhxQGed9Y1JtRpuvfUCHX30Aq1YcbwkafnyL2tk5Mj3ubXVtHfv+yWpYK2HHTsu\n08GDqZIH9ps379IHPvBjjY1lHiMQaNIXv/h6bdjw07x7L1zYrLvuukgrVhxfdFeORlDu55XdGSVb\nADSrmjuP5D6nd73rB7r//idmdP0115yjT3/63Ar1DgAAAEA9oSZFA8jOSpCkZHJUwWCzxsact2NG\nvve850dauDCz7ebGjau1aFFrXtHDYLBV8fiQJBWsFXHwYGpSQcSsQgPwiy9+RV4gkUqlvZ1EmvOu\nDQSadcwxCwvO4Kh2MchKqcTz6upq07HHLtTFF9+tP/1pZLx9JnU9ZiuRGNZnP/ufuvnmXd6MmLRG\nRqa/LuuDH1yhT33qnIYKoQAAAABUDiFFHcgtnpiVTE6uBZFpz5yTrUGxadNDk4KM3HoQM6kVUWwA\nXqww5sR6Fdl7l7MYpJ9mY1SyyOWKFccrnc6f9TTTuh6lyr6md9zxG33uczvG25PJ9BRX5SOcAAAA\nADAbk7dmgO9kQ4DpLFjQrGBw8uyFjRtXKxhs0VFHBbRgQbNuvPG88foOvb2dCgZbtGRJQMFgS9Fa\nEbkD8KGhlJLJUUWjfUokhgvWTRgbc7rpptcXvHeh55OdFTATsdigwuEeveENd+jEEzdr8+ZdM7q+\n3Mr1vAqZyfdqtgYHD+j9779PJ564WatXfzMvoJiOmdTRcZK++tXz9cwzf6ubbnoDAQUAAACAGWMm\nhY8UmxVQKASYKBhs1q23vlHvfvc9ee3J5Ii6u0/XwoXN2rjxAQUCTdqwYZuWLAmoq6ut5OKSU20j\nunLlsvHdH5qbTSMjad144+vU3X26Lr74lEn3jkSW5s0KkaRDh0aLzgoo9LoUml2S2WXC1N19esn3\nKafptuqcq0oWAn3727+nO+/cPatrV6/+c33/+xcTSgAAAACYM0IKn5iqlkHuFpBjY+mCgUUqldar\nXx3ylnYcWRZgZrrttkf10Y/+XNKRbUnXrr1Xxx67cLyI5XQDzOkG4F1dbXrhhcPjtSg2bPiplixZ\noK6utoL3nliwtVgB19zX5fDhMX3yk2eru/t0xeNDammZXI9j/fqf6OKLT5n0mNWogVHKtqfleIxy\n3C+RGNa2bU9o69a4vv3tx/Xcc6npL/K0tJi++92L1N//tM4/PzKvdunw0/IiAAAAoBGxu4cPJBLD\nBXfZmLhzQyIxrNtvH9QHP7ht0j2amqRY7E1at+6+vCKZRx0V0J/+lFK6wESMl7ykVem0K3nAnh3o\n5w7As9fN5Dn88Ie/11VX/VgvvnikAuOSJQFt3XpJXsHOQvfM3vfGG1+n9eu3jdfeyH2+P/7xkfsk\nEsPauXO/Lrrormn7Vi5+HsgODh7Qtdc+qH//98dndX1Tk/Rv//bXDVHkdKYatdgrAAAAUG3s7uFz\nUy2lyB3khkKL9M53tmnDhp+Ob/eZlU5Ll132w0n3Pnx4tGBAIWl8p4hSiztOtdyglOeQHeS1tDTl\nBRRS4WURhe4pZYqDbtjwU1199Spde+0v8o6Njh65T/bxmpo0Keio5M4Y5ZrtUE6Dgwe0du2P9NBD\nT8/q+pe/fKk2bfornXfeSb57btVQyaKoAAAAAI4gpPCBmdQyCIUW6eab3+DVX8iXSqXV2moKBlvG\nZzusX3+mbrhh+5SPn1vccefO/Xr++cM6+ugF40tBJj5+oUFZsefw3HOHlEgMS9KkGhJZgUCTens7\nJUn9/fvGA5CpanE453TDDdvHn2dWNHqaQqFFBWtWTOxbuXfG8OsMimj0Xt1yy6MzusZMam01/fVf\n/4U+/OGV82pJRyGlBokAAAAA5oaQwgcK1TK48cbXjQcHEwdB3d1nSDJ98IM/njSIDwZb9dWvnq9k\nclSrVi3TcccF9YUvDExZeHNkJK2f/exJnXPOt/JmaAQCTbr11jeWNKV94nM4dGhUo6NjuvTS7yuV\nSmvjxtUFZ0VIUlOT6YUXDisc7hmfSr9x42p1d5+u3t5OrV17rw4dyl/WMfHrrN7/v727j4+iPPcG\n/rt3Zja7SUAphJRaCLRqjdpCwou22iPIm3KqKEes9NSipA/BUzFNe2wtWnraKo9PtY1Ue46xhYKe\nNlZOUdRDfUkNtdXWBAhWbKyiENAPxpUqEPKyu7P388fuLLO7M/uS7GZnk9/388mHze7s7L25s9H7\nmuu+rg17sXbt52yzMMxbXNJdXKYTfIjfCtDQMAfV1ePzGrDw+Xpw++0vZhygmDWrHPfdN89xwZZ8\nynVRVCIiIiIiCmNNCgfp6DiC1tbD8Pl6sHbtizF73622WXR0HEFV1YMxdRkURUDTXCgqUqLPPXbM\nj7q656AoAqGQxGWXfRJPPvlWNCBy5ZWn49e/fs1yTF6vil27rkV3tx+lpW4cOnQMACyzLICTNSAW\nL34sJpDg8SjQdRmT9WAYNcoNv19PqC/h8Si4556LMWXKaLS0HML69buhaeECmi6XsMySMGpbTJ58\nSkI9C49HwbZtV9iOPf59HDhwFLt3d6G+fkfSOgR2tTNGjdIQDKZf82OwjJ89AOzffxRf/3qLbTDH\nSlmZB48+euWwzJrIRpZLsposRERERESUvmQ1KRikcIjYeg2xnRY0TUBRYgMPxuLIeB6QWHcBCHdi\nEAJwuxX09QXhcgkUF2vRThlHj/bh7rt32Y6rqEgBgISgQLIsi2ee2Y8lS7bhxImTx5eWaujtDSbU\n0jBew+1OrFNhMBb7DQ2zUV1djtJSN6ZPf8jy/ZoLYg50UZlsLqwKblq931TPySafrwc/+Ukb7rpr\np+XPN5VPfGI01q+fiy984ZM5GF3+ZbPgpVO39BARERERFRIGKRzO7kq8nfhFr1VGRTpcLtgW1RzI\nOICTC8L491JUpEBVXdFinWbLlp2Fxx7bl/L9WwUggHBwxuNRIIRIWIBmuqhMNRejR7uxZctlGDPG\ng8mTT0Fzc2fS2hfGc+I7l2TDyeBEG/TMph6f+cw4fPGLZ+HKK89AZeXYrI5rIHK1+E+36wwRERER\nEQ0ddvdwOLv6CXbMBft8vh60th6G2+3KOEgxmAAFEM6uMBcOtCtWGd62MQd1dYmtUwFg69Y3sH79\nHNTX70i62De/b3OnkdJSN7q7/ZYLXON7u/oe8VLNRV9fEIsXP4aiIgX9/TpCIZm03geQ3doFPl8P\nWloOYvv2N/Hf/92RUXBCUQSuuuoMfO97FzgiMGHIZWtPFrwkIiIiIiosDFI4QLIuFlYCgRD27z+K\n3/72Dfz0p7stW3oOBV2PXXy3t3dBj1s1u90ubNt2BRYsmAIAll1JFEVgypRT0Nm5Eo2NL+OOO/4C\nTVMStlqYF/vpXnnPdAFsNxelpRp0XSIY1NHXF7Kt9VBSomH16mlYv749ZptJNhbEjY17cMMNzcgk\n+am0VEMwGMKtt56P2tqpjluY57q1JwteEhEREREVFm73cAhz/QS/X7csMllaqsHv1xEMhmyzILxe\nBboegq5jQPUJhEDaYN+35gAAIABJREFUi2CXC/jWt2biG9+YiebmTssuHADwt79dj8rKsfD5evCx\nj/0XgsHEF/B4lOhCGghfAf/DHw7htttegKa5oOsnC1A2Nu5BXV0L3G4FwaB94GGgqf7xtSyMTh1b\nt76Rsp2rcX7jPQxm+4IRiCktdePBB/fizjvb0n6uogA/+9n8vHcYSaWt7TDmz9+Co0dPBqSyvT3G\n+H2J/z0iIiIiIqL8YE2KAmHODjBqHZgXylOmjMbllz+K/n77rAuvN5wcs2zZWdi8+dWMAhWXX/4J\n/OEPb8csGNOhaS4AEoFA4mu53S786U/LMHPmBMsFaTxja4jP14N161qhquGgzfr1F6O2dioaG/ck\nZGN4PAoOHqyN2XZy4MBRfPBBH66++okBLYDjMzV8vh5MmtSYEITRNAFVVbLe8eFkzQ2J3t7MtvGo\nqgt//etyR23psJPrmhHmIqjm36N0x8YimURERERE2ccgRYGKXyS1tR3GnDm/se0iMRiqKrBjxzWY\nP3+LbV0It9sFIZA0SGLFnEmRSYFQM6MVql2B0B/+8ALcdttnY7Z3WNWMsFoAp7MYtQuw/PCHF6C2\ndmpWFrNGC9EPP+zHddc9lfHPye1WoCiJxUOdLletPQcTAMllnQwiIiIiopGOhTMLVFlZccxiavLk\nUxAMDq7apdvtim4HMQsGJebOfQRnnHEq9u49kvA8RRHYuPGSaEeNdHk8Crq7wwv7srJibNiwEDU1\nT0NRBLq706+joWmupAVC77jjL/iXfzkzob6Bpgl4vaptfYh0F6OTJ5+Cnp7Y8aoqonUeBnulvbFx\nD772teaMu3Rcfvkn8LWvVWHixNG2xUMNTs0MMBdBzebYBlo0M9d1MoiIiIiIyB6DFAVk69bXB1Rn\nwqAoAs8990XMnfsb6HpisKO/X7cMUADh+hZf/vJ2fO5zE/Dii4cTHldVFxQlMctCCBFTpNC8IN29\n+z3U17eklTEQCIQwa9YEy3oWANDXp2P9+l0AYh9XFBcee2xx9PuqqvLo7WSLUSC2psT77/cm1Opw\nuVwpx22no+MIWlsPY9asCXj++UOWBUXtaJrAl75UiW9/+7y0t3Q4PTMgG4GeeAMtmsmOIERERERE\n+ZOXIIUQ4gCA4wB0AEEp5QwhxEcA/AbAZAAHAFwtpfxACCEArAewCEAPgOuklLvzMe6hFH/V26oW\ngxUjY8CKyyWwd69vUIGOF188DEVBwhV/TROQEli69Ew88cSbcLsVBAIh1NVVo729C1VV5dEFnrEg\nnTlzApYsOSPa0UNVXZbZFV6vig0bFqKyciw2bFhoW6Bz06a9CUGSvj4df/2rD2vXvpiwQLdbjDY2\nvox1616KHl9Tcy5+/vNXEgIkHo+K9vYujBnjySgDYPXqZtx3357o98liHcYYjFoja9acl3GXjpGa\nGWDO3Mmk0wo7ghARERER5U9ealJEghQzpJTvm+77EYB/SCnvFELcAmCMlPLbQohFAFYjHKQ4D8B6\nKeV5yc5f6DUp4q96NzTMQV3dc5bbHOIpikgahEj1eCZcrvBX0JQIYdSO+O1vX8f3v/9idGHvdruw\nadOl0av35voLp55ahIkTR+PQoWNoaTmEe+7ZBbdbgd+vW7bO9Pl6sHbtn3D//X+NGU9JSbjdpvnn\n5PEokBIx95k7cMTXLPB4FACwbTFqpmkCiuKCorgQCqXuGuHz9aCl5SC++MUnU57bGMu2bVektZUj\nmaHooOFk5qyVTDNPsl0ng4iIiIiIHFg40yZI8XcAs6WUh4UQEwDskFJ+SgjRGLndFH+c3fkLOUhh\nVeyvqEiBqoq0CmZ6PEpaC+xcGT3ajS1bLsPixY8ljMMIDjQ3d+K6634Xc7Xa5QpvGSkqUuH366iv\nn45vfGNG0voK8d02vF4VUsqY+6x+duYFelNTR8xYFEVEsiuS/wzDtT1kTMDH7Xbh7bdXWY7ZaIMJ\nyLQKj2qawObNi/JeQLLQDWabi1NreBARERERFbpkQYqBb6ofHAngGSHELiHEysh95abAw7sAjOIB\npwE4ZHru25H7YgghVgohdgohdvp8vlyNO+eMLQhmbrdiW4vBTIj0MgByySguqSgi4TG/X0d7exdq\nap5OSKcPhQC/P4Tjx/3o79dx552t2Lz5VbS1HYbP15NwrrKyYmzceAm8XhWjR7ujW0LM93k8ChYs\nqEgI7vT36ygtdQMA5s2rgMt1cqy6nrrlp6a5EAqFEjJS/P4QHn64Az5fD1544R38+7/vwC9+8Vfc\nfXcrVq1qRn+/bhug8HgUjBrlRlGRgltumYV33rkha1fujW0P8T+rfC28fb4e23nN9usY21yOHvWj\ntzeImpqn035dY0sSAxREREREREMnX4UzL5RSviOEGA/gWSHEa+YHpZRSCJFRioeU8gEADwDhTIrs\nDXVoWe+H13H77RfgO9/5Y9JghRO6yYZCEh9+2G9ZDFPXJQ4ePB4TFEjm5pv/gFGjNASDJ7dSmK9u\n23WFmDevAo2Ne3DHHS/hiSfeSjivEMD06Q+hoWE2PB4VmhabfWJsESkqCtfVqKk5Fxs27IWquuD3\n69D1UMwWF7Nvf/t51NW1ZDQXN944DWvXfi5rbUytzpOrDhqZGsoCniyASURERERUePISpJBSvhP5\n9z0hxKMAZgHoEkJMMG33eC9y+DsAJpqe/vHIfcOScdV7+fLtCATCK91AQMeaNX+EprkQDOY3UyKV\nUAj40peeRMhmR8Nrr/3DsrOInePHw5kZNTVP49ixftTX74i2ITXqVVjVVVi3rtU2q8S4f9WqZpSU\naDhxIpDw+F13/RMuumhidEF/7rnjUFfXAiGQNFCUKgvDoGkCP/7xbMybNzlaJ2GwC+dUAYBcdNDI\nxFAX8MykACa3dhAREREROcOQb/cQQpQIIUYZtwEsALAXwOMAlkcOWw5gW+T24wC+IsLOB3A0WT2K\n4cBogWnQdSAQSL0NwSniO3+Y3XvvLuh6KO1sCoPfH0RdXUs0db+vT8d3v/sCKioeQFNTR8wWAqst\nM3biAxSGtWtfjC5Yfb4e3HRTuHBptrbT3HvvXKxePT3tQo6pDHZrw1CwmhcjsyHbjN+DhobZKbe5\nNDV1oKLiAcyfvyX6+0RERERERPmRj0yKcgCPhjuLQgXwaynlU0KINgCPCCFqAHQCuDpy/HaEO3vs\nQ7gF6fVDP+Sh1d7eFc2iGG78/oG9L10HiooSAxu9vUFcd93v4HIJFBUp6O/X8fWvV6fVCSUZ87aA\n9vauhCvyA+H1KgiFgPXrL0Zt7dRBn8+svb0roZWpE7Y2mDMUhqq1p1V3nOrq8ZZZEiO1PSsRERER\nkVMNeZBCSvkWgIQVmpTyCIC5FvdLAF8bgqGRiaIkz4jIh0DAOlBgLHyNLIc772yDprmgaQJerxZt\nZVpW5kV9/Q4oikB3t3UGhfm1jMXzwYPHBjVuIcKFRF0uASklRo92D+p88YxFeXwdkFwEADJhtf1k\nw4aFCa09sxkMsAo61Ne32HYyYd0KIiIiIiJnyVfhTEqiqqo8urDLF6cFKABgyZLTsW3bm2ltuQgE\nQvB6VWzZchmqqsqjC84lS87EgQNHsXv3e6ivb4GmudDXF0QwGIrW0XC7XdHFc03NU9i4ce+Ax+x2\nCwACfn8IwUi1zUyu1MfXSrD63ipA4fEotgEA4xylpW50d/tzUofBLkOhs3MlOjtX5qz+Q6ZBh6HK\n7iAiIiIiovQwSOFAZWXF2LTpUqxY8VTeW4oOBbfbhcWLT8eWLa8nPW779v0AgKVLz8STT74VvRof\nDOqW22OMuhfmxalRPHLmzAlYsuQMtLd3YfHix2IKfbpcAtOmjUddXfOgAhRhAkVFKvx+f/QeTXOh\nvb0LY8Z4ki7U4zMRjC4j5syE008/NWFRXlKiYevWy7FgwRTbcwLhGideb/hPQLa7bCQLFuSyrWem\nQQejUG0uszuIiIiIiCh9Qjqhb2WWzZgxQ+7cuTPfwxi0Z57ZjyVLtuHECZt+l8NEUZELa9d+Ft//\n/otp1azwelU8++xS7Nv3AWbNmoA9e96zDei43S789KdzbWtAhH/Gj8cU0PR6Veh6aECZLIoCAAK6\nHn4fmuYCIGOCKG63K1pDw64Np8/Xg4qKByxbuZrHuWvXtZg+/aGY47xe1XJ7Q7Jz2j0nXrpdMKxe\nK93XGCwjEGMOOqQKwIzU7h4j9X0TERERUX4JIXZJKWdYPTbk3T0ofVVV5batPIeT/v4Qbr31hbSL\nauq6jrlzH0Fd3XOYPv0hAMDBg7W45ZZZUNXY4pp+fwirVj2LxsY9CedpaurA5Zc/mtDho7c3mDRA\noWkueDwKRo92w+0O174wukf87Gfz4HYr0WMDgRDi44DBYAh9fXrSLhzpdCjRNBe6u/3YsGFhTAeL\nhoY5OHDgaEbnTKfLRqZdMNasOS9lZ41cWLasEp2dK9HcvBS7dl2L008/NWWXEyO7ZiQt1NnVhIiI\niIiciNs9HGzr1tfh9w/vLIqBCAcz9GgHj5qap9HQMBv33LMLwaB1oOOmm57DlCmnoKTEjd2734XX\nq+KGG55FMO7HKwQSggrx7r13LpYsOSN6BRpA9LbVNof4McUHnqxqJlhtW4jX36+jtNSNZcsqMW9e\nRaTWRhfq61titoQYWQTJzpmqDkMmXTDM21SklLj55pmorZ06pAGAsrJiNDd3JhTuzOaWlkLGriZE\nRERE5FTMpHCoxsY9WLWq2ZEFLJ1GVV2oq2tJWr/D7w9h0aKtuPDCJtx0Uwv+z/9JDFAAqQMUpaUa\nqqvHR6+8A4gJVnzwQV/G20TiAwRGCn5Dw+yYTISamnNRVKTA4wlnarhcwPTpD6GpqQNlZcWYPPkU\n1NfvQG9v0DJLw6i/4PWq0XN4vWpaWQ5WWRiKIhKyL8yL36NH/ejr07Fu3UsZ/TyyIX4cdhkrI5XV\nfKaTTUNERERElGvMpHCgjo4juOmm5/I9jILR1xeE2+1Cf3/y44w6EYOh6zIaUDBnDPT0BCCEgNer\nIhjU4Xa74PGoloU9Nc0FRRFwu5WEQo3xxTIbGuagunp8JENiR2SLR3h7Sm/vyUwSI5MiVWcLc9ZF\nJt09rLIwursD2L37vWiwBnBOS0+njMOp2NWEiIiIiJyKmRQO09TUgaqqB/PafrTQBIOhnBUXNdef\nMDIOgHDBzRUrnopeqQ8EJPz+UPS2yyWwZctl6Oxcic2bF8VdtZa4556L0dy8FJ2dK6NbEKyu/tfX\nt6C01B3NkDACFPFjNLI50ll4GlkglZVj067DUFZWjIaG2Qn319e3xGQnJBuDz9eDtrbD8Pl6Ym7n\nQr4W4bl+X9lizqoZ6pohRERERETJMJPCQYxFqlFrgdKTiwY1JSUaQiGJDRsWYtq08WhtPRztJFJR\n8QBcLpF0e4nbrWDMGA/Kyooxbdr4mMcCAYn6+paEThd2V/9bWw8nFASNPV8omg2Ry3aa1dXlGDXK\njePHY9upmrMT7MZgrg/R2xuElBLFxVrOakXko7VofBaM02tgmLNq2N2DiIiIiJyCQQoHsVqkUn74\n/Tq++c0ZOHasH9OnPxTZTqIjFJJpZbkYgYOmpg5cf/1TCc9Jt1hmIBDC/v1Hcfx4YgZFaakGXZcx\ni+9cLjwnTz4FwWDq7IT4MQCItiM1/24fPRoOduSqYONQLsILtRBlWVmxo8dHRERERCMPgxQOUlrq\nTnp1ngBVFbYdPLIpEAjhzjtbo9+nGzjyeBQIIaLbQuwyY+y2YcRf/f/Sl87C97//54Tn33XXRbjo\noo9bLr5ztfDMJDvBPIZnntkPV5KNZenUijCKiWYabMjWzyLV67MGBhERERFRdjBI4RBGqrjLFU7r\nd7tFpNUmmQkhADj35yIlsHv3taisHIu2tsOWmTFFRYrt4j6+sOW0aZstX+cznxkXU7ByqGSanWD8\nXvf22tcMSVUrIt/bKNJ5fRaiJCIiIiLKDhbOdIDYVPHwYm4osgUKkbAvzTCocxYXK2kdq2kiWmyw\nqEiB1xsb53O7FbS2hgsnWi1c3W4X1q79LKZNG29bZNFoJ9raehhKesMaUkbhzVQBCvPvtZmmCWia\nSKtgY75biab7+ixESblSKMVYiYiIiLKFmRQOcODA0YSFXIjNPSzlouvJ449fiT17uvCDH/w5plWo\nWUmJimBQYv36OViy5MxopsP06Q/FHHf8uB+rV/8eN9zQjJqacxEMntzqIUR4/Lfe+ifceuufoCjh\nLT7xV+eNK/eq6kJvb+L71TSBqqryLP4Esse8LcJqC0RJiYatWy9HVVV5WtkYBw4cTSgaOpTbKKze\nQ29vEI2NL+O22z4bcywLUVK25TuLiIiIiCgfGKRwgNdf/yDfQxjRrrjiMbhcSAhQGIUply07C7/6\nVQc0zYW6uhYAArW1UwEgWqNBVV3RrhdGkcv77tsTc774LiS6nlg80rhttz1C0wQ2b140ZAtgI+hQ\nWurGoUPHAABVVeWWrx+/oGpomJMQVAqFZPT56byH3bu7EoqGJttGMdDaFXassmEA4I47/oLa2qlD\nVg+ERp5CLcZKRERENFgMUjhAS8uhfA9hyKlquL6EXeZCNgiRXntSXZfQLeqV/uu/VuLaa8/B3LmP\noL9fjxbAXLXqWQAStbXTsGxZJaZNG4+HH34NP/7xTpw4kdiFIx1GdgCAhCv3o0a5ccstMzFqlBvz\n5k1GZeXYrC/GrRhBB0Cit/fkD8gIlJiv6FotqOrrW9DQMBv19TsG1AbU5+tBff2OhPsbGmanFSTJ\nxlXnsrJirFlzHr773Rdi7ne7lWFVFDNbv09D8Xs5UrAYKxEREY1UQqaziiswM2bMkDt37sz3MNL2\n5JNv4rLLHs33MIaUogDTp5ejtbUrJ+f/+c/n44ILPo6pUzcNOBCiaQJCCMsr6S4X8Pzzy9DS0ol1\n61qhqsKyTWi6vF4VnZ0rAZxs12keh6oq0cV3Tc252LBhb05TwH2+noRxmHk8Cg4erI0ultraDmP+\n/C3RzBAAGD3ajebmpdGtH5kuXK3OOWqUG7///dKEoqFW4zV+poNd0Pl8PZg0qTGm8078uQt5cZ6t\n4A63JmRXLn+niYiIiPJNCLFLSjnD6jEWznSAL3zhk5g4sSTfwxhSuo6cBShUFdC0zCpOxtc9AMLb\nP+xqYIRCwIUXNuG7330Rvb3BmADFqFHhwonz50+Kec6nPz025ntFQUKRxfgCjEZLU3Phxvvu25Pz\nQpLGVVw7iiKimR9A8u4W6RbajGd1zmDQequH1XjN2SmDUVZWjI0bL7Esiunz9eD22/+MSZMaMX/+\nFlRUPICmpo5Bv+ZQyVZh0nwXOB2OWIyViIiIRipu93AAn68H777L/5nPlmAQ+OpXn4aiuKCqCgIB\n+/aXQHjB/W//Ng333//yoAtzlpZquPfeizFr1oSEopqvv/4hnnjiShw50otZsyZg3Div5dV3cwHG\nDz7ow9VXPwG/3x//UlFWKeDmWhLd3f6Mr/Db1WIw6LqMCRY0N3fGFAl1u12DXlAZi7SamqdTbhfJ\ndQtQq6KY8e1VjUyLQqobkK0tBdyakBssxkpEREQjEYMUDtDe3pXT2gwjUTAoYxbN8YqKFFxzzaeg\naQo2bdqLn/60PfqY16siGAwhEMg8YKHrEosWfSJyBT92Tvv7dVx11eP45S8vQWXlyawK42q/eQFi\nZFX4fD0pAyfxi/H4WhJGm9RM0u/NAQIpZcxWB00T2LjxkpitDjU1T8f8DrtcIloIdDDSXaRlEtAY\nKHNRTLv2qkBhLc6zFdzJdZBoJGMxViIiIhppGKRwgIMHj+d7CCOK2+3Cgw9eivb2Ltx5Z1vC48Gg\nDl0fWNCopuZclJUV4/33e2OKTRr6+/Xolfbm5k7LPfzx9Q3iF99GTQqrxbjV4tm4newKv1VNBXOA\nwNzdY+LE0eju9sPn60FZWbHlVfRsFpZMd5E2lFedrd6zoZAW59kK7gxFkIiIiIiIRgYGKRzArjgh\n5YbfH8KXv7zdNlNiMFktGzbsxdq1n0N3tx9er2p7pb29vcuyveCxY/2or98BVXXB79dx++0X4qKL\nPo5nn12Kffs+wKxZE1BZORZr134O7e3hmh5VVeXRcydbPBt1JOIXjskKHpoDBJWVY9HU1IErrtgW\nc+y8eRWOuYpujNUqOyWb7LbDeDxKwS3OsxXc4dYEIiIiIsoGBikcoLq6PPVBlFUD2cqRDiMQUFrq\nRihkHezw+3X8/e//gMslEp5bV9cSbXUKADff/AeoarjOhnnbBgDLwEKyWhLd3QHs3v1eTGcMq9ah\ndhkXdsc+9thiNDTMQX19S8qr6Ol0wRhMp4xsdphINg6rzIE1a85Dbe3UglycZ2tLAbcmEBEREdFg\nsQWpAzzzzH4sXPjbfA+DsmTFinPR1PQaQqEQ+vsTAwaaJuByiYTH3G4XFEVYbhMx83rVhDoR5taE\nxkLd6vXjWxhatfksLdXw3HNXJ7T5tDoWAEpKVIRCQEPDbFRXl1su6n2+HjQ27sG6da1JAwiDCTJk\ns2VjuuMo5NajRERERET5whakRENo48a96O0NWgYogPB2EqvHQiGZMkABhItSKkpsFoa53eayZZXo\n7FyJxsYFKC3VbI8DrLctGBkX8eyyNE6cCKK3N4j6+h2Wi/Wmpg5MmtQYbddq16Iy0zaWPl8P2toO\nRx/PVhvSTMYx0PaqNHjx809EREREwwODFA5QVVUOF2dixAsG08tq0vVQQmHP+BoQZWXFWLToE2kd\n19AwO+E16utboos/YzEIhLeaeL0qSkq0hOdYBQSMBb8568PgcoloXQ0gsyBDU1MHKioewPz5W1BR\n8QCamjqy1mEiW8EOyh2r+SciIiKi4YFLY8cQqQ8hQjhI8dWvfhper4rRo93wetWEGhDGNoSGhjlJ\njwOAKVNOQXFxbHkaY1EevxgEgM7Oldi69XJ4PErMc6wCAo2NL9sWhj1xIoDFix+LLjCTBRnMV83t\nMh2Ak0GUZO83FbbTdLZMM24yPTezM4iIiIjyi4UzHaCl5aBtkUXKPUUB9NS7LDJm1I4IBkNpZ0mk\nIxCQ2LBhL3btuhbd3f6ELRbx9RSS1YpoaurAihVPJWQ6BAIhlJa6LQtldnauxIIFU7Bx4yVJW076\nfD24446/JH0vfX16TKFOqzaW8a1a16w5L6GDiRFUyUaHCbbTdDarDjbG/A9mjrJZdJWIiIiIBo5B\nCgfo6uJVu3wpKlKwcGEFHn/8rayfOxSSePDBS7FixdMIBgNZPbemudDd7U8obmnVgaO+fodl8Ui7\nrRhGG83ubn/CYtDcxjRVQODAgaMoKlISzm90KzG/F7tzAogWwzTGsW7dS4gv+GvOdMhGhwm203Su\nXGS6ZNLlhoiIiIhyi9s9HGDKFKaR50t/v44nn8x+gAIIB0BOPbUIup55u9P4wpjxrLZBAEB7e1dC\na1O7egpWtRcARLN60imqaVc40ufrwQcf9MW0UwXCARBVTb5NxDgnAGzf/hZUNfH93Hrr+YPe1pEK\ni2I6k5Hpks35Zx2SRNz6QkRERPnCTAoHOHKkN/VBlDOhzGMIaenvD6Kl5SCCwfReoLhYQSAgsW7d\nhTjttFGoqXkaLle4e0a8K688PWEbRE3NufjFL16x3LphdZXZrltH+FzhbR0NDbOxalVzzOP19S1Y\nsuQM20WhOW0+FJJQVaCoSIWuS2zceAkApNwmYrQrVVUXjh+PzUIJBEKorZ2K2tqpec10YPvR/Ml2\npgvrkMTi1hciIiLKJxGfNj0czJgxQ+7cuTPfw0jbk0++icsuezTfw6AhoCiAlMkDIx6Pgm3brsDE\niaPx8MOv4Qc/+HPCMUIAHo9qW5TS4PWqaGiYHc3Wqaoqj1nQ3X13K2655Y8JXUBGj3ajuXkpAGDu\n3C04ftyf8JiR7WBerAPApEmNCYGS4mIVUiK62LFb4NvVyACA0lINui4dsWDiIm74MebUHDwbiXPq\n8/VEt1gZvF7VcssYERER0UAJIXZJKWdYPcZMCgfYv//DfA+BMuB2u6BpCk6cyLzORDoFOvv6dCxZ\n8jhCIYkf/OACy2OkRMoMjZISFTfeWI3Vq3+PQCAchNA0gc2bF2HZskqsXt2M++7bY/lc81Xk+Ncx\nPxa/WP/MZ8ZZBhh6esILHvM+/3RrZADhIMe6dRfimmsq875QYv2C4Yl1SMJyVZiUiIiIKF2sSeEA\n5eUl+R4CZeArXzkbfX3JMxgG68SJAHp7g1i79gV8+tNjLY8JBJIHKXRd4sc/bosGKMLPkbj++t/h\nhRfesQxQlJSoMXv8k+3/t2oF+dJL7yYdU7J9/nY1MoBwkONb33oezc2dSc8/FFi/YPhiHRJufSEi\nIqL8Y5DCAViTorD84hd7E7ZH5IqiCHR0/COtYzVNoKhIiQYTvv716ZatT/v7Q/jJT9osz/HNb85E\nZ+fKmDT3Zcsq0dm5Es3NS2MeSxZUsJNssWNXI8NgtCvNdyE/LuKGHxaJPCkXhUmJiIiIMsHtHg7w\nve/9Kd9DIIfq7k5/S4mqKti161p0d/sxefIp2LbtDdtjn3jCuqPJNdecZbkYsdqekSqoYPB4FLjd\nimWRzPjX2LBhYbQuQF9fEEKEgyoGJ6Sdx48z1fsiZ2N9kUTc+kJERET5xMKZeebz9WD8+P/M9zCo\nwKmqwIMPLoouLO6//2Vs3Lg36XMURcRkhNx44zTce++8jF43vtjg5z//MTzzzMGYc65d+7mMFjtG\nUc3SUjemT3/IsQX82N2j8GVaJJJzTkRERJQdLJzpYNzHTtmgqi68885xTJzYCEUBenpSV+jUdQmP\nR8GPfnQR5s2rQGWlde2LZIwrru3tXQDC3UPef78Xra2HMWvWhOg5M1nQmbM2zBkLfr+ONWvOy3iM\nuWKVXUKFJZMikcy4ICIiIhoarEmRZ6Wl7nwPgTKgKPl77aIiBT//+XwsX352wmNSAjff/Dz6+3Xb\nAIXL4tPudiulH7osAAAPwUlEQVQ4//xwMGGg+/KbmzuxePFjWLJkGyZNasSePe9h+fJzBxT0iGfU\nw7j55hkQQuDuu9tQUfEAmpo6Bn1uonTri1gViXVCfRQiIiKi4YhBijzr7vZbLh7JmdJpIQqEAwpW\nhAhvs0iHpomY4nW//OUl+OpXp+Kuu2bD641NgurvTz0wq9fu6wti8uRT0NTUgYqKBzB//paMggA+\nXw+WL9+Ovj4dJ04E0denY/ny7VlfvK1b15pygeiU4oe5GodT3t9wkm6RSHZ0ISIiIho63O6RZ+wI\nMLwIAfzxj8tw4oQf//zPWxO6a0gJhELWdWBUVUBKoLhYQzAYTie3Kl4XX7ixv1+HEOHuF8mEAyzx\n45F4//3e6FViI+19xYqnMHasB1VV5Um3NLS3d8W0OAXCbU7b27uwYMGUpONJVzop+U5Jxc/VOJzy\n/oajdIpEsqMLERER0dDhNfw8Kysrxuc/f1q+h0FZ4nIBZ545Bq2thy3bfwLhQEU8RQF+9at/xiuv\nXIff/35pQhvQeOa2oO3tX7EMfIg0Eja8Xg2trYcTrhL39em48sptmDixEY2NL+f1Kn6qBaJTUvGz\nNY74n7VT3t9wVlZWjJkzJ6TsPMO2nERERES5xyCFA/T1BVMfRAVB14Gf/GQn1q1rTfs5qgooigsr\nVz6D6dMfwr59H6KsrDjlFgxjYTVunBehUOwiXtME/vjHZdC05B/xQCCEWbMmWLYS7ekJor9fx6pV\nz+JjH/tPy3FUVZUnBDjcbheqqsoTzjfQQId5gVhSoiUsEJ2Sip+NcVjNuVPe30hnDgymCiISERER\n0cAVTJBCCHGJEOLvQoh9Qohb8j2ebErnijcVjoaGXVDV9D5axcUqFEWB3x+KuUre0XEk7avnjY17\nEIyLc3m9Gk6c8CN+e0fiWGejsnKsKQhgvQMsGITlOMrKirFp06UxAYRNmy617IwwkJoXZuF2yRLx\nbZOdkoo/2HHYZUyUlrod8f4odcYFEREREQ1eQQQphBAKgJ8BuBTA2QCWCSESWxwUKLttAeQ8Xq8C\nTRNJMxSMdpnp0HVpeZXcaguG1dVzn6/HMmvDeP3iYs32tUeNcqO6OpzxYFwl3rp1sW3RT7txGM9t\nabna8grzYLcr+Hw9WLHiqZjinPGBEiek4g92HHYZE93dfke8PyIiIiKioVAohTNnAdgnpXwLAIQQ\nDwNYDOBveR1Vlhw4cCzfQ6AkSkpUhELhrIPq6nKUlroxffpDCAQSt0gA4cDD+vUXo76+JRqwuPzy\nT2Lq1PFwuxWsXfsCNM2FQCCEhoY5qK9viXm+3RYMq6vnVkUlAeDWW89HVVW55TYOQzAYe76ysmIs\nWDAF69dfjFWrnrV9ntU4ysqKbRfN6RS+TKaxcU9CUdD456dT/HAoDGYcyTIxZs6c4Ij3R0RERESU\na4USpDgNwCHT928DOC9PY8mqjo4jeP/9vnwPY9jQNAFAwONREQyGUFNzLjZs2ItQSKbVplNRAFV1\nQVUVhEISDQ1zUF09PmFhaO6u0dsbgBDh1wwETnZeWLLkDMtF5fLl58TcP3q0O3ou4/nGFoz4++MX\np1YLW69XRW3t1IQuIFbjtFrs1tZOBSBRV3cyyCKlhNerJX2encFsg0iWKZJJoGQoDXQc8fMV/7N2\nyvsjIiIiIsolEb+/24mEEFcBuERK+dXI99cCOE9KeaPpmJUAVgLApEmTpnd2duZlrJnavHkvrrvu\nqXwPI+9UVWDhwsn43//dn/LYoiIF9fXTUVU1HsuX/y7mKrvXq2LXrmvR3e2PBgF8vh60t3dh8eLH\nYo7VNBekDEXrOWiawObNi9K+Yu3z9USPAzCoq9zmc5mfb3e/mdGe0rywNW+5GOg4s/n+Uo3RTlvb\nYcyfvwVHj/pj7v/hDy/Abbd9NuNxFIJ05pyIiIiIqJAJIXZJKWdYPlYgQYrPAvgPKeXCyPffAQAp\n5f+1On7GjBly586dQzjCgevoOIKzz/5lvoeREy5XuGtFUZGC/n4dy5efjfPO+xhqa5+BuRmFogCv\nvHI9KivHorFxT/QKfl9fEKGQjDl26dIz8bOfzYsu3jJZ/FodO29eBdrbuwCEO1UU6qKwEBa2Axmj\nz9eDiooH0Nt7sjKo16uis3OlY98nERERERElNxyCFCqA1wHMBfAOgDYAX5JSvmp1fCEFKQBg9epm\n3HffnpTHuVxAyL7EwIDNmlWOj360BI8//pbtMaoqcN115+DNN4+ipeVQzGMul4DLhWgw4rrrzsHS\npZ+KtqGMX5g2NXVgxYqnoCgCui6xceMlSa/8t7QcRFdXD+bNq0Bl5diEsWWy+C2ExTzFGmgWBhER\nEREROVPBBykAQAixCMA9ABQAG6WUd9gdW2hBCiCcUdHc3AmvV8WkSaPg94ewffubGDPGiy9/+WyM\nG+fFgQNHUVrqxqFDx/Dhh/04dqwfr776Pt59twcf/WgxzjlnHEaPLsKppxZFAwTbtr2B3bvfwxln\nnIpzzhmHiRNHo7vbj66uHrS1vYsFCybjggtOi47h0UffwIkTfkydOh6f/nQZDh0KF/U0ZxkY2yc+\n/LA/5rUyWfwzWECZ4O8LEREREdHwMSyCFJkoxCAFERERERER0UiQLEjhGurBEBERERERERFZYZCC\niIiIiIiIiByBQQoiIiIiIiIicgQGKYiIiIiIiIjIERikICIiIiIiIiJHYJCCiIiIiIiIiByBQQoi\nIiIiIiIicgQGKYiIiIiIiIjIERikICIiIiIiIiJHYJCCiIiIiIiIiByBQQoiIiIiIiIicgQGKYiI\niIiIiIjIERikICIiIiIiIiJHYJCCiIiIiIiIiByBQQoiIiIiIiIicgQhpcz3GLJOCOED0JnvcQzA\nOADv53sQlHOc55GB8zwycJ5HBs7zyMB5Hhk4z8Mf57gwVEgpy6weGJZBikIlhNgppZyR73FQbnGe\nRwbO88jAeR4ZOM8jA+d5ZOA8D3+c48LH7R5ERERERERE5AgMUhARERERERGRIzBI4SwP5HsANCQ4\nzyMD53lk4DyPDJznkYHzPDJwnoc/znGBY00KIiIiIiIiInIEZlIQERERERERkSMwSOEQQohLhBB/\nF0LsE0Lcku/x0MAJIQ4IIV4RQuwRQuyM3PcRIcSzQog3Iv+OidwvhBA/jcz7X4UQ1fkdPdkRQmwU\nQrwnhNhrui/jeRVCLI8c/4YQYnk+3gvZs5nn/xBCvBP5TO8RQiwyPfadyDz/XQix0HQ//6Y7mBBi\nohCiRQjxNyHEq0KIusj9/EwPI0nmmZ/pYUQI4RFCtAohXo7M8/cj908RQrwUmbPfCCHckfuLIt/v\nizw+2XQuy/mn/Esyz5uEEPtNn+dpkfv5d7uQSSn5lecvAAqANwF8AoAbwMsAzs73uPg14Pk8AGBc\n3H0/AnBL5PYtAP5f5PYiAL8DIACcD+ClfI+fX7bz+k8AqgHsHei8AvgIgLci/46J3B6T7/fGr5Tz\n/B8A/t3i2LMjf6+LAEyJ/B1X+Dfd+V8AJgCojtweBeD1yHzyMz2MvpLMMz/Tw+gr8rksjdzWALwU\n+Zw+AuCayP33A7ghcvvfANwfuX0NgN8km/98vz9+pZznTQCusjief7cL+IuZFM4wC8A+KeVbUko/\ngIcBLM7zmCi7FgPYHLm9GcAVpvsflGF/AXCqEGJCPgZIyUkpnwfwj7i7M53XhQCelVL+Q0r5AYBn\nAVyS+9FTumzm2c5iAA9LKfullPsB7EP47zn/pjuclPKwlHJ35PZxAB0ATgM/08NKknm2w890AYp8\nLrsj32qRLwngYgD/E7k//vNsfM7/B8BcIYSA/fyTAySZZzv8u13AGKRwhtMAHDJ9/zaS/0eUnE0C\neEYIsUsIsTJyX7mU8nDk9rsAyiO3OfeFLdN55XwXrhsj6aIbjS0A4DwPC5FU7yqEr8rxMz1Mxc0z\nwM/0sCKEUIQQewC8h/Ci800AH0opg5FDzHMWnc/I40cBjAXn2fHi51lKaXye74h8nhuEEEWR+/h5\nLmAMUhBl34VSymoAlwL4mhDin8wPSiklkkd+qQBxXoe1/wLwSQDTABwG8OP8DoeyRQhRCuC3AL4u\npTxmfoyf6eHDYp75mR5mpJS6lHIagI8jnP1wVp6HRDkQP89CiHMBfAfh+Z6J8BaOb+dxiJQlDFI4\nwzsAJpq+/3jkPipAUsp3Iv++B+BRhP9j2WVs44j8+17kcM59Yct0XjnfBUhK2RX5H6MQgJ/jZPov\n57mACSE0hBeuv5JSbo3czc/0MGM1z/xMD19Syg8BtAD4LMLp/WrkIfOcRecz8vgpAI6A81wwTPN8\nSWRbl5RS9gP4Jfh5HhYYpHCGNgBnRKoQuxEu4vN4nsdEAyCEKBFCjDJuA1gAYC/C82lUD14OYFvk\n9uMAvhKpQHw+gKOmVGNyvkzn9WkAC4QQYyLpxQsi95GDxdWJuRLhzzQQnudrIpXipwA4A0Ar+Dfd\n8SL7zzcA6JBS/sT0ED/Tw4jdPPMzPbwIIcqEEKdGbnsBzEe4/kgLgKsih8V/no3P+VUAnotkTtnN\nPzmAzTy/ZgosC4Trjpg/z/y7XaDU1IdQrkkpg0KIGxH+gCgANkopX83zsGhgygE8Gv47CRXAr6WU\nTwkh2gA8IoSoAdAJ4OrI8dsRrj68D0APgOuHfsiUDiFEE4DZAMYJId4G8D0AdyKDeZVS/kMI8UOE\n/4cXAH4gpUy3SCMNAZt5nh1paSYR7t5TCwBSyleFEI8A+BuAIICvSSn1yHn4N93ZLgBwLYBXIvub\nAWAN+JkebuzmeRk/08PKBACbhRAKwhdgH5FSPimE+BuAh4UQtwNoRzhghci/Dwkh9iFcKPkaIPn8\nkyPYzfNzQogyhLt47AGwKnI8/24XMBEOHBIRERERERER5Re3exARERERERGRIzBIQURERERERESO\nwCAFERERERERETkCgxRERERERERE5AgMUhARERERERGRIzBIQURERI4lhLhCCCGFEGfleyxERESU\newxSEBERkZMtA/CnyL9EREQ0zAkpZb7HQERERJRACFEK4O8A5gB4Qkr5qTwPiYiIiHKMmRRERETk\nVIsBPCWlfB3AESHE9HwPiIiIiHKLQQoiIiJyqmUAHo7cfhjc8kFERDTscbsHEREROY4Q4iMA3gbg\nAyABKJF/KyT/54WIiGjYYiYFEREROdFVAB6SUlZIKSdLKScC2A/g83keFxEREeUQgxRERETkRMsA\nPBp332/BLR9ERETDGrd7EBEREREREZEjMJOCiIiIiIiIiByBQQoiIiIiIiIicgQGKYiIiIiIiIjI\nERikICIiIiIiIiJHYJCCiIiIiIiIiByBQQoiIiIiIiIicgQGKYiIiIiIiIjIERikICIiIiIiIiJH\n+P+HbmyU/I/JkAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1296x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fsTyWd6qacT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 9. Data로 부터 BERT용 input 만들기\n",
        "# Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
        "data_InputExamples = data.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
        "                                                                   text_a = x[FIRST_COLUMN], \n",
        "                                                                   text_b = x[SECOND_COLUMN], \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "label_list = [0,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjxu50n1u3u0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "5a8d0eb3-9031-43f2-a6e6-26e9e7cc9b51"
      },
      "source": [
        "# 10. BERT Hub와 Tokenizer 정의\n",
        "# This is a path to an uncased (all lowercase) version of BERT\n",
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "\n",
        "def create_tokenizer_from_hub_module():\n",
        "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "  with tf.Graph().as_default():\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    with tf.Session() as sess:\n",
        "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                            tokenization_info[\"do_lower_case\"]])\n",
        "      \n",
        "  return bert.tokenization.FullTokenizer(\n",
        "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEFrcqJcvyOk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "498f47b5-fb0d-4fbf-9b79-f1e766a047fb"
      },
      "source": [
        "# 11. 토크나이저 실험\n",
        "tokenizer.tokenize(\"This here's an example of using the BERT tokenizer\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this',\n",
              " 'here',\n",
              " \"'\",\n",
              " 's',\n",
              " 'an',\n",
              " 'example',\n",
              " 'of',\n",
              " 'using',\n",
              " 'the',\n",
              " 'bert',\n",
              " 'token',\n",
              " '##izer']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcSJORQ0v1of",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a060015c-4daa-4e3d-d03e-ac095a6a1b7c"
      },
      "source": [
        "# 12. 하이퍼 파라미터 세팅\n",
        "\n",
        "# We'll set sequences to be at most 128 tokens long.\n",
        "MAX_SEQ_LENGTH = 128\n",
        "# Convert our train and test features to InputFeatures that BERT understands.\n",
        "train_features = bert.run_classifier.convert_examples_to_features(data_InputExamples, label_list,MAX_SEQ_LENGTH, tokenizer)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 10000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 10000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] despite being a sequel to the more potent original , this is more of a comical remake of friday the 13th concerning the further antics of psycho ##pathic angela , killing more nu ##bil ##e teens for their \" im ##moral ##ity \" at a camp . < br / > < br / > pamela springsteen ( sister of bruce ) looks [SEP] there are some pretty dar ##n funny sex scenes with some pretty dar ##n attractive girls , but the movie ' s so ( un ##int ##ent ##ional ##ly ) comedic rather than suspense ##ful , it ' s a stink ##er . < br / > < br / > * out of * * * * . < br / [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] despite being a sequel to the more potent original , this is more of a comical remake of friday the 13th concerning the further antics of psycho ##pathic angela , killing more nu ##bil ##e teens for their \" im ##moral ##ity \" at a camp . < br / > < br / > pamela springsteen ( sister of bruce ) looks [SEP] there are some pretty dar ##n funny sex scenes with some pretty dar ##n attractive girls , but the movie ' s so ( un ##int ##ent ##ional ##ly ) comedic rather than suspense ##ful , it ' s a stink ##er . < br / > < br / > * out of * * * * . < br / [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2750 2108 1037 8297 2000 1996 2062 16834 2434 1010 2023 2003 2062 1997 1037 29257 12661 1997 5958 1996 6122 7175 1996 2582 27440 1997 18224 25940 10413 1010 4288 2062 16371 14454 2063 13496 2005 2037 1000 10047 22049 3012 1000 2012 1037 3409 1012 1026 7987 1013 1028 1026 7987 1013 1028 17217 26002 1006 2905 1997 5503 1007 3504 102 2045 2024 2070 3492 18243 2078 6057 3348 5019 2007 2070 3492 18243 2078 8702 3057 1010 2021 1996 3185 1005 1055 2061 1006 4895 18447 4765 19301 2135 1007 21699 2738 2084 23873 3993 1010 2009 1005 1055 1037 27136 2121 1012 1026 7987 1013 1028 1026 7987 1013 1028 1008 2041 1997 1008 1008 1008 1008 1012 1026 7987 1013 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2750 2108 1037 8297 2000 1996 2062 16834 2434 1010 2023 2003 2062 1997 1037 29257 12661 1997 5958 1996 6122 7175 1996 2582 27440 1997 18224 25940 10413 1010 4288 2062 16371 14454 2063 13496 2005 2037 1000 10047 22049 3012 1000 2012 1037 3409 1012 1026 7987 1013 1028 1026 7987 1013 1028 17217 26002 1006 2905 1997 5503 1007 3504 102 2045 2024 2070 3492 18243 2078 6057 3348 5019 2007 2070 3492 18243 2078 8702 3057 1010 2021 1996 3185 1005 1055 2061 1006 4895 18447 4765 19301 2135 1007 21699 2738 2084 23873 3993 1010 2009 1005 1055 1037 27136 2121 1012 1026 7987 1013 1028 1026 7987 1013 1028 1008 2041 1997 1008 1008 1008 1008 1012 1026 7987 1013 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the cl ##iche ##d poly ##nesian males drink , fight and make a stream of sex ##ist , stupid and un ##fu ##nn ##y remarks [SEP] real life poly ##nesian ##s are much fun ##nier than these stereo ##type ##d , cardboard characters [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the cl ##iche ##d poly ##nesian males drink , fight and make a stream of sex ##ist , stupid and un ##fu ##nn ##y remarks [SEP] real life poly ##nesian ##s are much fun ##nier than these stereo ##type ##d , cardboard characters [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 18856 17322 2094 26572 20281 3767 4392 1010 2954 1998 2191 1037 5460 1997 3348 2923 1010 5236 1998 4895 11263 10695 2100 12629 102 2613 2166 26572 20281 2015 2024 2172 4569 14862 2084 2122 12991 13874 2094 1010 19747 3494 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 18856 17322 2094 26572 20281 3767 4392 1010 2954 1998 2191 1037 5460 1997 3348 2923 1010 5236 1998 4895 11263 10695 2100 12629 102 2613 2166 26572 20281 2015 2024 2172 4569 14862 2084 2122 12991 13874 2094 1010 19747 3494 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] although in some aspects seven pounds is solid and interesting in some of its narrative style , gabriel ##e mu ##cci ##no ' s project is rather med ##io ##cre [SEP] the movie becomes more and more sap ##py and mani ##pu ##lative as it move toward the end : hearts human and emotional , eyes physical and metaphor ##ical [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] although in some aspects seven pounds is solid and interesting in some of its narrative style , gabriel ##e mu ##cci ##no ' s project is rather med ##io ##cre [SEP] the movie becomes more and more sap ##py and mani ##pu ##lative as it move toward the end : hearts human and emotional , eyes physical and metaphor ##ical [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2348 1999 2070 5919 2698 7038 2003 5024 1998 5875 1999 2070 1997 2049 7984 2806 1010 6127 2063 14163 14693 3630 1005 1055 2622 2003 2738 19960 3695 16748 102 1996 3185 4150 2062 1998 2062 20066 7685 1998 23624 14289 26255 2004 2009 2693 2646 1996 2203 1024 8072 2529 1998 6832 1010 2159 3558 1998 19240 7476 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2348 1999 2070 5919 2698 7038 2003 5024 1998 5875 1999 2070 1997 2049 7984 2806 1010 6127 2063 14163 14693 3630 1005 1055 2622 2003 2738 19960 3695 16748 102 1996 3185 4150 2062 1998 2062 20066 7685 1998 23624 14289 26255 2004 2009 2693 2646 1996 2203 1024 8072 2529 1998 6832 1010 2159 3558 1998 19240 7476 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] what ever possessed martin sc ##or ##ces ##e to remake this film ? and not only did he remake it , completely ruin it ? the non ##sen ##sic ##al decision to make the character played by robert den ##iro ( in his most over ##don ##e performance , and that ' s saying a lot ) into a religious fan ##atic is ridiculous , and exemplary of attitudes harbor ##ed by hollywood ( and mr [SEP] sc ##or ##ces ##e especially ) - attitudes that com ##pel writers to think that the best way to make a character insane is to tattoo a cr ##uc ##if ##ix on his back [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] what ever possessed martin sc ##or ##ces ##e to remake this film ? and not only did he remake it , completely ruin it ? the non ##sen ##sic ##al decision to make the character played by robert den ##iro ( in his most over ##don ##e performance , and that ' s saying a lot ) into a religious fan ##atic is ridiculous , and exemplary of attitudes harbor ##ed by hollywood ( and mr [SEP] sc ##or ##ces ##e especially ) - attitudes that com ##pel writers to think that the best way to make a character insane is to tattoo a cr ##uc ##if ##ix on his back [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2054 2412 8679 3235 8040 2953 9623 2063 2000 12661 2023 2143 1029 1998 2025 2069 2106 2002 12661 2009 1010 3294 10083 2009 1029 1996 2512 5054 19570 2389 3247 2000 2191 1996 2839 2209 2011 2728 7939 9711 1006 1999 2010 2087 2058 5280 2063 2836 1010 1998 2008 1005 1055 3038 1037 2843 1007 2046 1037 3412 5470 12070 2003 9951 1010 1998 27792 1997 13818 6496 2098 2011 5365 1006 1998 2720 102 8040 2953 9623 2063 2926 1007 1011 13818 2008 4012 11880 4898 2000 2228 2008 1996 2190 2126 2000 2191 1037 2839 9577 2003 2000 11660 1037 13675 14194 10128 7646 2006 2010 2067 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2054 2412 8679 3235 8040 2953 9623 2063 2000 12661 2023 2143 1029 1998 2025 2069 2106 2002 12661 2009 1010 3294 10083 2009 1029 1996 2512 5054 19570 2389 3247 2000 2191 1996 2839 2209 2011 2728 7939 9711 1006 1999 2010 2087 2058 5280 2063 2836 1010 1998 2008 1005 1055 3038 1037 2843 1007 2046 1037 3412 5470 12070 2003 9951 1010 1998 27792 1997 13818 6496 2098 2011 5365 1006 1998 2720 102 8040 2953 9623 2063 2926 1007 1011 13818 2008 4012 11880 4898 2000 2228 2008 1996 2190 2126 2000 2191 1037 2839 9577 2003 2000 11660 1037 13675 14194 10128 7646 2006 2010 2067 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] despite an overall pleasing plot and expensive production one wonders how a director can make so many clumsy cultural mistakes [SEP] where were the japanese wardrobe and cultural consultants ? not on the payroll apparently [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] despite an overall pleasing plot and expensive production one wonders how a director can make so many clumsy cultural mistakes [SEP] where were the japanese wardrobe and cultural consultants ? not on the payroll apparently [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2750 2019 3452 24820 5436 1998 6450 2537 2028 16278 2129 1037 2472 2064 2191 2061 2116 22902 3451 12051 102 2073 2020 1996 2887 17828 1998 3451 22283 1029 2025 2006 1996 26854 4593 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2750 2019 3452 24820 5436 1998 6450 2537 2028 16278 2129 1037 2472 2064 2191 2061 2116 22902 3451 12051 102 2073 2020 1996 2887 17828 1998 3451 22283 1029 2025 2006 1996 26854 4593 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASh45ZuP2MsY",
        "colab_type": "text"
      },
      "source": [
        "# Creating a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1yFYXvd2RhB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 13. 기존 BERT 로 모델 생성 \n",
        "\n",
        "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
        "                 num_labels):\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "\n",
        "  bert_module = hub.Module(\n",
        "      BERT_MODEL_HUB,\n",
        "      trainable=True)\n",
        "  bert_inputs = dict(\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      segment_ids=segment_ids)\n",
        "  bert_outputs = bert_module(\n",
        "      inputs=bert_inputs,\n",
        "      signature=\"tokens\",\n",
        "      as_dict=True)\n",
        "\n",
        "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
        "  # Use \"sequence_outputs\" for token-level output.\n",
        "  output_layer = bert_outputs[\"pooled_output\"]\n",
        "\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "  # Create our own layer to tune for politeness data.\n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "\n",
        "    # Dropout helps prevent overfitting\n",
        "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "    # Convert labels into one-hot encoding\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
        "    if is_predicting:\n",
        "      return (predicted_labels, log_probs)\n",
        "\n",
        "    # If we're train/eval, compute loss between predicted and actual label\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "    return (loss, predicted_labels, log_probs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSO7J_mqmsQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model_fn_builder actually creates our model function\n",
        "# using the passed parameters for num_labels, learning_rate, etc.\n",
        "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
        "                     num_warmup_steps):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "\n",
        "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "    \n",
        "    # TRAIN and EVAL\n",
        "    if not is_predicting:\n",
        "\n",
        "      (loss, predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      train_op = bert.optimization.create_optimizer(\n",
        "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
        "\n",
        "      # Calculate evaluation metrics. \n",
        "      def metric_fn(label_ids, predicted_labels):\n",
        "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "        f1_score = tf.contrib.metrics.f1_score(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        auc = tf.metrics.auc(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        recall = tf.metrics.recall(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        precision = tf.metrics.precision(\n",
        "            label_ids,\n",
        "            predicted_labels) \n",
        "        true_pos = tf.metrics.true_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        true_neg = tf.metrics.true_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)   \n",
        "        false_pos = tf.metrics.false_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)  \n",
        "        false_neg = tf.metrics.false_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            \"f1_score\": f1_score,\n",
        "            \"auc\": auc,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"true_positives\": true_pos,\n",
        "            \"true_negatives\": true_neg,\n",
        "            \"false_positives\": false_pos,\n",
        "            \"false_negatives\": false_neg\n",
        "        }\n",
        "\n",
        "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
        "\n",
        "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode,\n",
        "          loss=loss,\n",
        "          train_op=train_op)\n",
        "      else:\n",
        "          return tf.estimator.EstimatorSpec(mode=mode,\n",
        "            loss=loss,\n",
        "            eval_metric_ops=eval_metrics)\n",
        "    else:\n",
        "      (predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      predictions = {\n",
        "          'probabilities': log_probs,\n",
        "          'labels': predicted_labels\n",
        "      }\n",
        "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "  # Return the actual model function in the closure\n",
        "  return model_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fUu3ymTmx_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 14. 하이퍼 파라미터 세팅\n",
        "\n",
        "# Compute train and warmup steps from batch size\n",
        "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 3.0\n",
        "# Warmup is a period of time where hte learning rate \n",
        "# is small and gradually increases--usually helps training.\n",
        "WARMUP_PROPORTION = 0.1\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 500\n",
        "SAVE_SUMMARY_STEPS = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJxNb8IYm0Ry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 15. 하이퍼 파라미터 세팅\n",
        "\n",
        "# Compute # train and warmup steps from batch size\n",
        "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XOqr7_7m2ST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 16. 모델 저장을 위한 세팅\n",
        "\n",
        "import os\n",
        "\n",
        "# Specify outpit directory and number of checkpoint steps to save\n",
        "run_config = tf.estimator.RunConfig(\n",
        "    model_dir=os.getcwd(),\n",
        "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Grn7n_dum3_i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "f4c20cf1-c289-4eee-f211-1faaedc3de84"
      },
      "source": [
        "# 17. 모델 변수 정의\n",
        "\n",
        "model_fn = model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "estimator = tf.estimator.Estimator(\n",
        "  model_fn=model_fn,\n",
        "  config=run_config,\n",
        "  params={\"batch_size\": BATCH_SIZE})"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': '/content', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7face821d7b8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': '/content', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7face821d7b8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiIwJ_lNm81x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 18. 모델 설정 \n",
        "\n",
        "# Create an input function for training. drop_remainder = True for using TPUs.\n",
        "train_input_fn = bert.run_classifier.input_fn_builder(\n",
        "    features=train_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap5hJqeonAxR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4dd3e69b-a201-4717-a7b5-f282abbe4370"
      },
      "source": [
        "# 19. 시작!\n",
        "\n",
        "print(f'Beginning Training!')\n",
        "current_time = datetime.now()\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print(\"Training took time \", datetime.now() - current_time)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning Training!\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-38-ca03218f28a6>:34: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-38-ca03218f28a6>:34: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/metrics/python/metrics/classification.py:162: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/metrics/python/metrics/classification.py:162: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into /content/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into /content/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.77991927, step = 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.77991927, step = 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 97 vs previous value: 97. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 97 vs previous value: 97. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.0229756\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.0229756\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.00019607582, step = 101 (4352.448 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.00019607582, step = 101 (4352.448 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 101 vs previous value: 101. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 101 vs previous value: 101. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 105 vs previous value: 105. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 105 vs previous value: 105. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 107 vs previous value: 107. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 107 vs previous value: 107. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 109 vs previous value: 109. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 109 vs previous value: 109. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.023163\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.023163\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.00011099613, step = 201 (4317.227 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.00011099613, step = 201 (4317.227 sec)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sqrp61W7nCU3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "2145ce38-504c-41cb-dd9d-282302e63a03"
      },
      "source": [
        "\"\"\" 테스트용\n",
        "test_input_fn = run_classifier.input_fn_builder(\n",
        "    features=test_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=False)\n",
        "\"\"\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-46c2b4b0352f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m test_input_fn = run_classifier.input_fn_builder(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mseq_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_SEQ_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'run_classifier' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Atp8LqcRnDkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 20. BERT 모델로 prediction을 받는 함수\n",
        "\n",
        "def getPrediction(in_sentences):\n",
        "  labels = [\"Wrong\", \"Right\"]\n",
        "  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x[0], text_b = x[1], label = 0) for x in in_sentences] # here, \"\" is just a dummy label\n",
        "  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
        "  predictions = estimator.predict(predict_input_fn)\n",
        "  return [(sentence, prediction['probabilities'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)] \n",
        "\n",
        "  # Return 형태를 보면 문장, 확률, 레이블 반환"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nle8ckl8o1vR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 예시\n",
        "\n",
        "ANSWER  = [3,2,1]\n",
        "\n",
        "start = \"Movies may be said to support the dominant culture and to serve as a means for its reproduction over time.\"\n",
        "\n",
        "sent1 = \"The bad guys are usually punished; the romantic couple almost always find each other despite the obstacles and difficulties they encounter on the path to true love; and the way we wish the world to be is how, in the movies, it more often than not winds up being. No doubt it is this utopian aspect of movies that accounts for why we enjoy them so much.\"\n",
        "sent2 = \"The simple answer to this question is that movies do more than present two-hour civics lessons or editorials on responsible behavior. They also tell stories that, in the end, we find satisfying.\"\n",
        "sent3 = \"But one may ask why audiences would find such movies enjoyable if all they do is give cultural directives and prescriptions for proper living. Most of us would likely grow tired of such didactic movies and would probably come to see them as propaganda, similar to the cultural artwork that was common in the Soviet Union and other autocratic societies.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2OcqZIenIAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_sentences = [\n",
        "  (start, sent1), # Start -> any sentence \n",
        "  (start, sent2),\n",
        "  (start, sent3),\n",
        "  (sent1, sent2), # Any -> Any \n",
        "  (sent1, sent3),\n",
        "  (sent2, sent1),\n",
        "  (sent2, sent3),\n",
        "  (sent3, snet1),\n",
        "  (sent3, sent2)\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mm1SmvanLEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = getPrediction(pred_sentences)ㄴ"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2nBASBmE6VL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}